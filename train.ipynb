{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados esperados:\n",
    " - input: \n",
    "    - avg_runtime\n",
    "    - input_complexity\n",
    " - output: \n",
    "    - p_cores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset/train_data.csv\")\n",
    "df_test = pd.read_csv(\"dataset/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train[['input', 'average_runtime']]\n",
    "y_train = df_train['cores']\n",
    "\n",
    "x_test = df_test[['input', 'average_runtime']]\n",
    "y_test = df_test['cores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(2, activation=\"relu\", dropout=0.2, input_shape=(x_train.shape[1],1)))\n",
    "model.add(tf.keras.layers.Dense(16))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss=\"mse\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=1, epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(x_train)\n",
    "test_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
    "\n",
    "ax.plot(np.arange(0, 100), history.history[\"loss\"], label=\"train_loss\",linestyle='--')\n",
    "ax.set_title(\"Training Loss and Accuracy\")\n",
    "ax.set_xlabel(\"Epoch #\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cores</th>\n",
       "      <th>input</th>\n",
       "      <th>average_runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.249501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.365511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.497553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.700741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7.320535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>18.991211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>75.998050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>165.176281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>340.393590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cores  input  average_runtime\n",
       "0       32      0         0.123057\n",
       "1       32      1         0.249501\n",
       "2       32      2         0.365511\n",
       "3       32      3         0.497553\n",
       "4       32      4         0.700741\n",
       "..     ...    ...              ...\n",
       "315      1      5         7.320535\n",
       "316      1      6        18.991211\n",
       "317      1      7        75.998050\n",
       "318      1      8       165.176281\n",
       "319      1      9       340.393590\n",
       "\n",
       "[320 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.read_csv(\"dataset/clean_data.csv\")\n",
    "df_clean['cores'] = df_clean['cores']/df_clean['cores'].max()\n",
    "df_clean['input'] = df_clean['input']/df_clean['input'].max()\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean[['input', 'average_runtime']].values\n",
    "y = df_clean['cores'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 - 1s - loss: 412.6702 - val_loss: 385.7479 - 861ms/epoch - 123ms/step\n",
      "Epoch 2/500\n",
      "7/7 - 0s - loss: 398.6385 - val_loss: 374.8702 - 48ms/epoch - 7ms/step\n",
      "Epoch 3/500\n",
      "7/7 - 0s - loss: 387.0935 - val_loss: 364.9607 - 46ms/epoch - 7ms/step\n",
      "Epoch 4/500\n",
      "7/7 - 0s - loss: 378.1602 - val_loss: 355.8913 - 43ms/epoch - 6ms/step\n",
      "Epoch 5/500\n",
      "7/7 - 0s - loss: 370.1861 - val_loss: 348.1417 - 43ms/epoch - 6ms/step\n",
      "Epoch 6/500\n",
      "7/7 - 0s - loss: 364.7598 - val_loss: 341.2755 - 44ms/epoch - 6ms/step\n",
      "Epoch 7/500\n",
      "7/7 - 0s - loss: 359.4748 - val_loss: 336.0150 - 44ms/epoch - 6ms/step\n",
      "Epoch 8/500\n",
      "7/7 - 0s - loss: 355.6845 - val_loss: 331.3683 - 93ms/epoch - 13ms/step\n",
      "Epoch 9/500\n",
      "7/7 - 0s - loss: 352.3986 - val_loss: 327.6097 - 47ms/epoch - 7ms/step\n",
      "Epoch 10/500\n",
      "7/7 - 0s - loss: 349.8760 - val_loss: 324.1637 - 43ms/epoch - 6ms/step\n",
      "Epoch 11/500\n",
      "7/7 - 0s - loss: 347.3721 - val_loss: 321.4069 - 40ms/epoch - 6ms/step\n",
      "Epoch 12/500\n",
      "7/7 - 0s - loss: 345.0803 - val_loss: 318.8972 - 44ms/epoch - 6ms/step\n",
      "Epoch 13/500\n",
      "7/7 - 0s - loss: 342.7795 - val_loss: 316.5547 - 45ms/epoch - 6ms/step\n",
      "Epoch 14/500\n",
      "7/7 - 0s - loss: 340.6078 - val_loss: 314.8354 - 44ms/epoch - 6ms/step\n",
      "Epoch 15/500\n",
      "7/7 - 0s - loss: 338.4443 - val_loss: 312.7333 - 46ms/epoch - 7ms/step\n",
      "Epoch 16/500\n",
      "7/7 - 0s - loss: 336.2176 - val_loss: 310.7000 - 44ms/epoch - 6ms/step\n",
      "Epoch 17/500\n",
      "7/7 - 0s - loss: 334.2163 - val_loss: 308.7514 - 43ms/epoch - 6ms/step\n",
      "Epoch 18/500\n",
      "7/7 - 0s - loss: 331.9424 - val_loss: 306.4361 - 42ms/epoch - 6ms/step\n",
      "Epoch 19/500\n",
      "7/7 - 0s - loss: 329.8252 - val_loss: 304.2051 - 40ms/epoch - 6ms/step\n",
      "Epoch 20/500\n",
      "7/7 - 0s - loss: 327.5403 - val_loss: 302.1242 - 50ms/epoch - 7ms/step\n",
      "Epoch 21/500\n",
      "7/7 - 0s - loss: 325.4724 - val_loss: 300.2931 - 48ms/epoch - 7ms/step\n",
      "Epoch 22/500\n",
      "7/7 - 0s - loss: 323.1943 - val_loss: 297.8975 - 48ms/epoch - 7ms/step\n",
      "Epoch 23/500\n",
      "7/7 - 0s - loss: 320.8906 - val_loss: 295.8500 - 39ms/epoch - 6ms/step\n",
      "Epoch 24/500\n",
      "7/7 - 0s - loss: 318.7061 - val_loss: 293.7469 - 40ms/epoch - 6ms/step\n",
      "Epoch 25/500\n",
      "7/7 - 0s - loss: 316.4453 - val_loss: 291.3203 - 43ms/epoch - 6ms/step\n",
      "Epoch 26/500\n",
      "7/7 - 0s - loss: 314.2144 - val_loss: 288.9751 - 42ms/epoch - 6ms/step\n",
      "Epoch 27/500\n",
      "7/7 - 0s - loss: 311.8631 - val_loss: 287.1765 - 43ms/epoch - 6ms/step\n",
      "Epoch 28/500\n",
      "7/7 - 0s - loss: 309.4594 - val_loss: 285.1540 - 41ms/epoch - 6ms/step\n",
      "Epoch 29/500\n",
      "7/7 - 0s - loss: 307.0329 - val_loss: 282.6272 - 41ms/epoch - 6ms/step\n",
      "Epoch 30/500\n",
      "7/7 - 0s - loss: 304.4347 - val_loss: 280.2378 - 40ms/epoch - 6ms/step\n",
      "Epoch 31/500\n",
      "7/7 - 0s - loss: 301.9355 - val_loss: 277.6754 - 41ms/epoch - 6ms/step\n",
      "Epoch 32/500\n",
      "7/7 - 0s - loss: 299.3869 - val_loss: 275.2565 - 41ms/epoch - 6ms/step\n",
      "Epoch 33/500\n",
      "7/7 - 0s - loss: 296.6627 - val_loss: 272.0355 - 41ms/epoch - 6ms/step\n",
      "Epoch 34/500\n",
      "7/7 - 0s - loss: 293.7965 - val_loss: 269.4994 - 41ms/epoch - 6ms/step\n",
      "Epoch 35/500\n",
      "7/7 - 0s - loss: 290.4495 - val_loss: 266.0213 - 39ms/epoch - 6ms/step\n",
      "Epoch 36/500\n",
      "7/7 - 0s - loss: 286.8502 - val_loss: 262.5507 - 41ms/epoch - 6ms/step\n",
      "Epoch 37/500\n",
      "7/7 - 0s - loss: 282.9275 - val_loss: 258.4908 - 41ms/epoch - 6ms/step\n",
      "Epoch 38/500\n",
      "7/7 - 0s - loss: 278.5340 - val_loss: 254.5002 - 42ms/epoch - 6ms/step\n",
      "Epoch 39/500\n",
      "7/7 - 0s - loss: 273.1782 - val_loss: 249.7221 - 40ms/epoch - 6ms/step\n",
      "Epoch 40/500\n",
      "7/7 - 0s - loss: 268.0734 - val_loss: 243.8619 - 41ms/epoch - 6ms/step\n",
      "Epoch 41/500\n",
      "7/7 - 0s - loss: 262.2470 - val_loss: 237.7075 - 40ms/epoch - 6ms/step\n",
      "Epoch 42/500\n",
      "7/7 - 0s - loss: 255.9806 - val_loss: 231.5241 - 40ms/epoch - 6ms/step\n",
      "Epoch 43/500\n",
      "7/7 - 0s - loss: 249.7727 - val_loss: 225.4517 - 43ms/epoch - 6ms/step\n",
      "Epoch 44/500\n",
      "7/7 - 0s - loss: 243.8559 - val_loss: 219.2599 - 82ms/epoch - 12ms/step\n",
      "Epoch 45/500\n",
      "7/7 - 0s - loss: 238.2137 - val_loss: 213.9983 - 49ms/epoch - 7ms/step\n",
      "Epoch 46/500\n",
      "7/7 - 0s - loss: 232.3330 - val_loss: 209.1099 - 38ms/epoch - 5ms/step\n",
      "Epoch 47/500\n",
      "7/7 - 0s - loss: 226.5451 - val_loss: 203.6878 - 41ms/epoch - 6ms/step\n",
      "Epoch 48/500\n",
      "7/7 - 0s - loss: 220.6005 - val_loss: 197.8855 - 41ms/epoch - 6ms/step\n",
      "Epoch 49/500\n",
      "7/7 - 0s - loss: 214.4475 - val_loss: 191.3961 - 40ms/epoch - 6ms/step\n",
      "Epoch 50/500\n",
      "7/7 - 0s - loss: 207.8154 - val_loss: 184.4819 - 39ms/epoch - 6ms/step\n",
      "Epoch 51/500\n",
      "7/7 - 0s - loss: 201.0856 - val_loss: 178.1505 - 42ms/epoch - 6ms/step\n",
      "Epoch 52/500\n",
      "7/7 - 0s - loss: 194.7399 - val_loss: 171.9864 - 40ms/epoch - 6ms/step\n",
      "Epoch 53/500\n",
      "7/7 - 0s - loss: 188.0197 - val_loss: 166.2141 - 40ms/epoch - 6ms/step\n",
      "Epoch 54/500\n",
      "7/7 - 0s - loss: 182.0938 - val_loss: 160.4762 - 43ms/epoch - 6ms/step\n",
      "Epoch 55/500\n",
      "7/7 - 0s - loss: 176.2295 - val_loss: 155.0624 - 42ms/epoch - 6ms/step\n",
      "Epoch 56/500\n",
      "7/7 - 0s - loss: 171.0699 - val_loss: 149.8000 - 39ms/epoch - 6ms/step\n",
      "Epoch 57/500\n",
      "7/7 - 0s - loss: 165.7167 - val_loss: 144.9262 - 41ms/epoch - 6ms/step\n",
      "Epoch 58/500\n",
      "7/7 - 0s - loss: 160.6988 - val_loss: 140.3246 - 42ms/epoch - 6ms/step\n",
      "Epoch 59/500\n",
      "7/7 - 0s - loss: 156.0693 - val_loss: 135.9687 - 45ms/epoch - 6ms/step\n",
      "Epoch 60/500\n",
      "7/7 - 0s - loss: 151.7812 - val_loss: 131.8632 - 39ms/epoch - 6ms/step\n",
      "Epoch 61/500\n",
      "7/7 - 0s - loss: 147.5768 - val_loss: 128.0169 - 43ms/epoch - 6ms/step\n",
      "Epoch 62/500\n",
      "7/7 - 0s - loss: 143.4824 - val_loss: 124.5346 - 41ms/epoch - 6ms/step\n",
      "Epoch 63/500\n",
      "7/7 - 0s - loss: 140.1079 - val_loss: 121.2126 - 40ms/epoch - 6ms/step\n",
      "Epoch 64/500\n",
      "7/7 - 0s - loss: 136.3136 - val_loss: 118.2856 - 40ms/epoch - 6ms/step\n",
      "Epoch 65/500\n",
      "7/7 - 0s - loss: 133.3052 - val_loss: 115.3934 - 66ms/epoch - 9ms/step\n",
      "Epoch 66/500\n",
      "7/7 - 0s - loss: 130.4011 - val_loss: 112.6522 - 42ms/epoch - 6ms/step\n",
      "Epoch 67/500\n",
      "7/7 - 0s - loss: 127.3871 - val_loss: 110.2855 - 40ms/epoch - 6ms/step\n",
      "Epoch 68/500\n",
      "7/7 - 0s - loss: 124.8249 - val_loss: 108.0602 - 41ms/epoch - 6ms/step\n",
      "Epoch 69/500\n",
      "7/7 - 0s - loss: 122.3636 - val_loss: 106.0363 - 41ms/epoch - 6ms/step\n",
      "Epoch 70/500\n",
      "7/7 - 0s - loss: 120.1913 - val_loss: 104.1053 - 42ms/epoch - 6ms/step\n",
      "Epoch 71/500\n",
      "7/7 - 0s - loss: 118.0240 - val_loss: 102.3666 - 40ms/epoch - 6ms/step\n",
      "Epoch 72/500\n",
      "7/7 - 0s - loss: 115.9529 - val_loss: 100.9026 - 41ms/epoch - 6ms/step\n",
      "Epoch 73/500\n",
      "7/7 - 0s - loss: 114.2758 - val_loss: 99.4995 - 40ms/epoch - 6ms/step\n",
      "Epoch 74/500\n",
      "7/7 - 0s - loss: 112.5184 - val_loss: 98.1839 - 46ms/epoch - 7ms/step\n",
      "Epoch 75/500\n",
      "7/7 - 0s - loss: 111.0307 - val_loss: 96.9772 - 43ms/epoch - 6ms/step\n",
      "Epoch 76/500\n",
      "7/7 - 0s - loss: 109.5750 - val_loss: 95.8960 - 40ms/epoch - 6ms/step\n",
      "Epoch 77/500\n",
      "7/7 - 0s - loss: 108.3411 - val_loss: 94.8599 - 40ms/epoch - 6ms/step\n",
      "Epoch 78/500\n",
      "7/7 - 0s - loss: 107.1014 - val_loss: 93.9921 - 43ms/epoch - 6ms/step\n",
      "Epoch 79/500\n",
      "7/7 - 0s - loss: 105.9942 - val_loss: 93.2470 - 40ms/epoch - 6ms/step\n",
      "Epoch 80/500\n",
      "7/7 - 0s - loss: 104.8601 - val_loss: 92.5156 - 40ms/epoch - 6ms/step\n",
      "Epoch 81/500\n",
      "7/7 - 0s - loss: 103.8282 - val_loss: 91.8643 - 40ms/epoch - 6ms/step\n",
      "Epoch 82/500\n",
      "7/7 - 0s - loss: 102.7799 - val_loss: 91.3140 - 42ms/epoch - 6ms/step\n",
      "Epoch 83/500\n",
      "7/7 - 0s - loss: 102.0253 - val_loss: 90.8225 - 41ms/epoch - 6ms/step\n",
      "Epoch 84/500\n",
      "7/7 - 0s - loss: 101.1365 - val_loss: 90.3241 - 44ms/epoch - 6ms/step\n",
      "Epoch 85/500\n",
      "7/7 - 0s - loss: 100.4220 - val_loss: 89.9006 - 40ms/epoch - 6ms/step\n",
      "Epoch 86/500\n",
      "7/7 - 0s - loss: 99.6409 - val_loss: 89.5644 - 40ms/epoch - 6ms/step\n",
      "Epoch 87/500\n",
      "7/7 - 0s - loss: 99.0352 - val_loss: 89.1875 - 83ms/epoch - 12ms/step\n",
      "Epoch 88/500\n",
      "7/7 - 0s - loss: 98.4126 - val_loss: 88.9276 - 44ms/epoch - 6ms/step\n",
      "Epoch 89/500\n",
      "7/7 - 0s - loss: 97.7682 - val_loss: 88.6805 - 39ms/epoch - 6ms/step\n",
      "Epoch 90/500\n",
      "7/7 - 0s - loss: 97.2813 - val_loss: 88.4251 - 39ms/epoch - 6ms/step\n",
      "Epoch 91/500\n",
      "7/7 - 0s - loss: 96.6351 - val_loss: 88.1986 - 44ms/epoch - 6ms/step\n",
      "Epoch 92/500\n",
      "7/7 - 0s - loss: 96.2142 - val_loss: 88.0187 - 44ms/epoch - 6ms/step\n",
      "Epoch 93/500\n",
      "7/7 - 0s - loss: 95.6598 - val_loss: 87.7895 - 42ms/epoch - 6ms/step\n",
      "Epoch 94/500\n",
      "7/7 - 0s - loss: 95.1460 - val_loss: 87.5841 - 41ms/epoch - 6ms/step\n",
      "Epoch 95/500\n",
      "7/7 - 0s - loss: 94.6713 - val_loss: 87.4045 - 41ms/epoch - 6ms/step\n",
      "Epoch 96/500\n",
      "7/7 - 0s - loss: 94.2011 - val_loss: 87.2142 - 41ms/epoch - 6ms/step\n",
      "Epoch 97/500\n",
      "7/7 - 0s - loss: 93.7626 - val_loss: 87.0374 - 44ms/epoch - 6ms/step\n",
      "Epoch 98/500\n",
      "7/7 - 0s - loss: 93.2681 - val_loss: 86.9085 - 42ms/epoch - 6ms/step\n",
      "Epoch 99/500\n",
      "7/7 - 0s - loss: 92.6988 - val_loss: 86.7938 - 42ms/epoch - 6ms/step\n",
      "Epoch 100/500\n",
      "7/7 - 0s - loss: 92.1316 - val_loss: 86.6617 - 40ms/epoch - 6ms/step\n",
      "Epoch 101/500\n",
      "7/7 - 0s - loss: 91.7130 - val_loss: 86.3865 - 41ms/epoch - 6ms/step\n",
      "Epoch 102/500\n",
      "7/7 - 0s - loss: 91.1456 - val_loss: 86.1367 - 40ms/epoch - 6ms/step\n",
      "Epoch 103/500\n",
      "7/7 - 0s - loss: 90.7358 - val_loss: 85.7856 - 42ms/epoch - 6ms/step\n",
      "Epoch 104/500\n",
      "7/7 - 0s - loss: 90.2440 - val_loss: 85.5146 - 39ms/epoch - 6ms/step\n",
      "Epoch 105/500\n",
      "7/7 - 0s - loss: 89.7465 - val_loss: 85.1675 - 41ms/epoch - 6ms/step\n",
      "Epoch 106/500\n",
      "7/7 - 0s - loss: 89.1908 - val_loss: 84.8128 - 39ms/epoch - 6ms/step\n",
      "Epoch 107/500\n",
      "7/7 - 0s - loss: 88.7340 - val_loss: 84.5219 - 39ms/epoch - 6ms/step\n",
      "Epoch 108/500\n",
      "7/7 - 0s - loss: 88.2377 - val_loss: 84.2154 - 41ms/epoch - 6ms/step\n",
      "Epoch 109/500\n",
      "7/7 - 0s - loss: 87.7747 - val_loss: 83.9258 - 41ms/epoch - 6ms/step\n",
      "Epoch 110/500\n",
      "7/7 - 0s - loss: 87.4160 - val_loss: 83.6130 - 41ms/epoch - 6ms/step\n",
      "Epoch 111/500\n",
      "7/7 - 0s - loss: 86.9691 - val_loss: 83.3780 - 42ms/epoch - 6ms/step\n",
      "Epoch 112/500\n",
      "7/7 - 0s - loss: 86.5345 - val_loss: 83.1741 - 43ms/epoch - 6ms/step\n",
      "Epoch 113/500\n",
      "7/7 - 0s - loss: 86.2214 - val_loss: 82.9451 - 40ms/epoch - 6ms/step\n",
      "Epoch 114/500\n",
      "7/7 - 0s - loss: 85.9224 - val_loss: 82.6311 - 41ms/epoch - 6ms/step\n",
      "Epoch 115/500\n",
      "7/7 - 0s - loss: 85.4382 - val_loss: 82.4990 - 41ms/epoch - 6ms/step\n",
      "Epoch 116/500\n",
      "7/7 - 0s - loss: 85.0939 - val_loss: 82.3394 - 41ms/epoch - 6ms/step\n",
      "Epoch 117/500\n",
      "7/7 - 0s - loss: 84.7570 - val_loss: 82.1538 - 43ms/epoch - 6ms/step\n",
      "Epoch 118/500\n",
      "7/7 - 0s - loss: 84.4141 - val_loss: 81.9856 - 43ms/epoch - 6ms/step\n",
      "Epoch 119/500\n",
      "7/7 - 0s - loss: 84.1263 - val_loss: 81.8576 - 40ms/epoch - 6ms/step\n",
      "Epoch 120/500\n",
      "7/7 - 0s - loss: 83.8504 - val_loss: 81.6797 - 41ms/epoch - 6ms/step\n",
      "Epoch 121/500\n",
      "7/7 - 0s - loss: 83.5201 - val_loss: 81.4802 - 41ms/epoch - 6ms/step\n",
      "Epoch 122/500\n",
      "7/7 - 0s - loss: 83.2729 - val_loss: 81.2703 - 40ms/epoch - 6ms/step\n",
      "Epoch 123/500\n",
      "7/7 - 0s - loss: 82.9870 - val_loss: 81.1068 - 41ms/epoch - 6ms/step\n",
      "Epoch 124/500\n",
      "7/7 - 0s - loss: 82.6309 - val_loss: 80.9169 - 42ms/epoch - 6ms/step\n",
      "Epoch 125/500\n",
      "7/7 - 0s - loss: 82.3904 - val_loss: 80.7759 - 41ms/epoch - 6ms/step\n",
      "Epoch 126/500\n",
      "7/7 - 0s - loss: 82.1668 - val_loss: 80.5804 - 85ms/epoch - 12ms/step\n",
      "Epoch 127/500\n",
      "7/7 - 0s - loss: 81.8758 - val_loss: 80.3649 - 48ms/epoch - 7ms/step\n",
      "Epoch 128/500\n",
      "7/7 - 0s - loss: 81.5726 - val_loss: 80.1412 - 40ms/epoch - 6ms/step\n",
      "Epoch 129/500\n",
      "7/7 - 0s - loss: 81.3607 - val_loss: 79.9344 - 38ms/epoch - 5ms/step\n",
      "Epoch 130/500\n",
      "7/7 - 0s - loss: 81.0485 - val_loss: 79.6791 - 44ms/epoch - 6ms/step\n",
      "Epoch 131/500\n",
      "7/7 - 0s - loss: 80.8005 - val_loss: 79.4688 - 41ms/epoch - 6ms/step\n",
      "Epoch 132/500\n",
      "7/7 - 0s - loss: 80.4976 - val_loss: 79.3171 - 41ms/epoch - 6ms/step\n",
      "Epoch 133/500\n",
      "7/7 - 0s - loss: 80.2434 - val_loss: 79.1961 - 41ms/epoch - 6ms/step\n",
      "Epoch 134/500\n",
      "7/7 - 0s - loss: 80.0231 - val_loss: 78.9946 - 42ms/epoch - 6ms/step\n",
      "Epoch 135/500\n",
      "7/7 - 0s - loss: 79.7471 - val_loss: 78.6670 - 42ms/epoch - 6ms/step\n",
      "Epoch 136/500\n",
      "7/7 - 0s - loss: 79.4284 - val_loss: 78.4263 - 42ms/epoch - 6ms/step\n",
      "Epoch 137/500\n",
      "7/7 - 0s - loss: 79.1194 - val_loss: 78.2009 - 40ms/epoch - 6ms/step\n",
      "Epoch 138/500\n",
      "7/7 - 0s - loss: 78.8236 - val_loss: 77.9647 - 40ms/epoch - 6ms/step\n",
      "Epoch 139/500\n",
      "7/7 - 0s - loss: 78.6241 - val_loss: 77.8199 - 41ms/epoch - 6ms/step\n",
      "Epoch 140/500\n",
      "7/7 - 0s - loss: 78.3319 - val_loss: 77.6003 - 41ms/epoch - 6ms/step\n",
      "Epoch 141/500\n",
      "7/7 - 0s - loss: 78.0217 - val_loss: 77.3509 - 40ms/epoch - 6ms/step\n",
      "Epoch 142/500\n",
      "7/7 - 0s - loss: 77.7643 - val_loss: 77.1278 - 40ms/epoch - 6ms/step\n",
      "Epoch 143/500\n",
      "7/7 - 0s - loss: 77.5273 - val_loss: 76.8987 - 40ms/epoch - 6ms/step\n",
      "Epoch 144/500\n",
      "7/7 - 0s - loss: 77.2548 - val_loss: 76.7077 - 41ms/epoch - 6ms/step\n",
      "Epoch 145/500\n",
      "7/7 - 0s - loss: 77.0307 - val_loss: 76.4993 - 41ms/epoch - 6ms/step\n",
      "Epoch 146/500\n",
      "7/7 - 0s - loss: 76.8127 - val_loss: 76.3473 - 39ms/epoch - 6ms/step\n",
      "Epoch 147/500\n",
      "7/7 - 0s - loss: 76.5974 - val_loss: 76.1539 - 40ms/epoch - 6ms/step\n",
      "Epoch 148/500\n",
      "7/7 - 0s - loss: 76.3526 - val_loss: 75.9929 - 38ms/epoch - 5ms/step\n",
      "Epoch 149/500\n",
      "7/7 - 0s - loss: 76.1361 - val_loss: 75.8259 - 42ms/epoch - 6ms/step\n",
      "Epoch 150/500\n",
      "7/7 - 0s - loss: 75.9811 - val_loss: 75.7290 - 39ms/epoch - 6ms/step\n",
      "Epoch 151/500\n",
      "7/7 - 0s - loss: 75.8401 - val_loss: 75.5189 - 40ms/epoch - 6ms/step\n",
      "Epoch 152/500\n",
      "7/7 - 0s - loss: 75.5834 - val_loss: 75.4651 - 39ms/epoch - 6ms/step\n",
      "Epoch 153/500\n",
      "7/7 - 0s - loss: 75.4281 - val_loss: 75.4185 - 40ms/epoch - 6ms/step\n",
      "Epoch 154/500\n",
      "7/7 - 0s - loss: 75.2917 - val_loss: 75.2083 - 39ms/epoch - 6ms/step\n",
      "Epoch 155/500\n",
      "7/7 - 0s - loss: 75.0222 - val_loss: 75.1243 - 41ms/epoch - 6ms/step\n",
      "Epoch 156/500\n",
      "7/7 - 0s - loss: 74.8561 - val_loss: 75.0363 - 40ms/epoch - 6ms/step\n",
      "Epoch 157/500\n",
      "7/7 - 0s - loss: 74.7109 - val_loss: 74.9241 - 41ms/epoch - 6ms/step\n",
      "Epoch 158/500\n",
      "7/7 - 0s - loss: 74.5162 - val_loss: 74.8210 - 40ms/epoch - 6ms/step\n",
      "Epoch 159/500\n",
      "7/7 - 0s - loss: 74.3616 - val_loss: 74.6746 - 41ms/epoch - 6ms/step\n",
      "Epoch 160/500\n",
      "7/7 - 0s - loss: 74.2511 - val_loss: 74.6238 - 39ms/epoch - 6ms/step\n",
      "Epoch 161/500\n",
      "7/7 - 0s - loss: 74.0677 - val_loss: 74.4950 - 39ms/epoch - 6ms/step\n",
      "Epoch 162/500\n",
      "7/7 - 0s - loss: 73.8950 - val_loss: 74.3528 - 40ms/epoch - 6ms/step\n",
      "Epoch 163/500\n",
      "7/7 - 0s - loss: 73.7566 - val_loss: 74.2050 - 82ms/epoch - 12ms/step\n",
      "Epoch 164/500\n",
      "7/7 - 0s - loss: 73.6769 - val_loss: 74.0773 - 43ms/epoch - 6ms/step\n",
      "Epoch 165/500\n",
      "7/7 - 0s - loss: 73.4971 - val_loss: 73.9996 - 40ms/epoch - 6ms/step\n",
      "Epoch 166/500\n",
      "7/7 - 0s - loss: 73.3505 - val_loss: 73.9596 - 43ms/epoch - 6ms/step\n",
      "Epoch 167/500\n",
      "7/7 - 0s - loss: 73.2399 - val_loss: 73.8101 - 40ms/epoch - 6ms/step\n",
      "Epoch 168/500\n",
      "7/7 - 0s - loss: 73.1111 - val_loss: 73.7601 - 62ms/epoch - 9ms/step\n",
      "Epoch 169/500\n",
      "7/7 - 0s - loss: 72.9773 - val_loss: 73.5803 - 42ms/epoch - 6ms/step\n",
      "Epoch 170/500\n",
      "7/7 - 0s - loss: 72.8185 - val_loss: 73.5068 - 39ms/epoch - 6ms/step\n",
      "Epoch 171/500\n",
      "7/7 - 0s - loss: 72.6754 - val_loss: 73.4349 - 40ms/epoch - 6ms/step\n",
      "Epoch 172/500\n",
      "7/7 - 0s - loss: 72.5528 - val_loss: 73.3422 - 43ms/epoch - 6ms/step\n",
      "Epoch 173/500\n",
      "7/7 - 0s - loss: 72.4449 - val_loss: 73.2825 - 42ms/epoch - 6ms/step\n",
      "Epoch 174/500\n",
      "7/7 - 0s - loss: 72.3252 - val_loss: 73.1971 - 40ms/epoch - 6ms/step\n",
      "Epoch 175/500\n",
      "7/7 - 0s - loss: 72.2215 - val_loss: 73.0837 - 39ms/epoch - 6ms/step\n",
      "Epoch 176/500\n",
      "7/7 - 0s - loss: 72.0899 - val_loss: 72.9230 - 41ms/epoch - 6ms/step\n",
      "Epoch 177/500\n",
      "7/7 - 0s - loss: 72.0737 - val_loss: 72.8384 - 39ms/epoch - 6ms/step\n",
      "Epoch 178/500\n",
      "7/7 - 0s - loss: 71.9411 - val_loss: 72.8426 - 44ms/epoch - 6ms/step\n",
      "Epoch 179/500\n",
      "7/7 - 0s - loss: 71.8046 - val_loss: 72.7479 - 43ms/epoch - 6ms/step\n",
      "Epoch 180/500\n",
      "7/7 - 0s - loss: 71.6915 - val_loss: 72.6392 - 40ms/epoch - 6ms/step\n",
      "Epoch 181/500\n",
      "7/7 - 0s - loss: 71.5971 - val_loss: 72.5458 - 41ms/epoch - 6ms/step\n",
      "Epoch 182/500\n",
      "7/7 - 0s - loss: 71.4964 - val_loss: 72.5180 - 39ms/epoch - 6ms/step\n",
      "Epoch 183/500\n",
      "7/7 - 0s - loss: 71.4287 - val_loss: 72.4271 - 41ms/epoch - 6ms/step\n",
      "Epoch 184/500\n",
      "7/7 - 0s - loss: 71.3055 - val_loss: 72.3506 - 40ms/epoch - 6ms/step\n",
      "Epoch 185/500\n",
      "7/7 - 0s - loss: 71.2479 - val_loss: 72.2648 - 41ms/epoch - 6ms/step\n",
      "Epoch 186/500\n",
      "7/7 - 0s - loss: 71.2146 - val_loss: 72.2734 - 44ms/epoch - 6ms/step\n",
      "Epoch 187/500\n",
      "7/7 - 0s - loss: 71.1388 - val_loss: 72.1230 - 41ms/epoch - 6ms/step\n",
      "Epoch 188/500\n",
      "7/7 - 0s - loss: 70.9903 - val_loss: 72.0610 - 42ms/epoch - 6ms/step\n",
      "Epoch 189/500\n",
      "7/7 - 0s - loss: 70.9109 - val_loss: 72.0190 - 41ms/epoch - 6ms/step\n",
      "Epoch 190/500\n",
      "7/7 - 0s - loss: 70.8572 - val_loss: 71.8650 - 41ms/epoch - 6ms/step\n",
      "Epoch 191/500\n",
      "7/7 - 0s - loss: 70.7274 - val_loss: 71.7977 - 37ms/epoch - 5ms/step\n",
      "Epoch 192/500\n",
      "7/7 - 0s - loss: 70.6430 - val_loss: 71.7416 - 44ms/epoch - 6ms/step\n",
      "Epoch 193/500\n",
      "7/7 - 0s - loss: 70.5805 - val_loss: 71.6328 - 41ms/epoch - 6ms/step\n",
      "Epoch 194/500\n",
      "7/7 - 0s - loss: 70.5819 - val_loss: 71.5126 - 43ms/epoch - 6ms/step\n",
      "Epoch 195/500\n",
      "7/7 - 0s - loss: 70.4163 - val_loss: 71.4598 - 39ms/epoch - 6ms/step\n",
      "Epoch 196/500\n",
      "7/7 - 0s - loss: 70.3023 - val_loss: 71.3679 - 43ms/epoch - 6ms/step\n",
      "Epoch 197/500\n",
      "7/7 - 0s - loss: 70.2522 - val_loss: 71.1916 - 74ms/epoch - 11ms/step\n",
      "Epoch 198/500\n",
      "7/7 - 0s - loss: 70.1702 - val_loss: 71.0748 - 53ms/epoch - 8ms/step\n",
      "Epoch 199/500\n",
      "7/7 - 0s - loss: 70.0657 - val_loss: 71.0482 - 41ms/epoch - 6ms/step\n",
      "Epoch 200/500\n",
      "7/7 - 0s - loss: 69.9813 - val_loss: 70.9758 - 42ms/epoch - 6ms/step\n",
      "Epoch 201/500\n",
      "7/7 - 0s - loss: 69.9654 - val_loss: 70.7810 - 40ms/epoch - 6ms/step\n",
      "Epoch 202/500\n",
      "7/7 - 0s - loss: 69.7923 - val_loss: 70.6355 - 39ms/epoch - 6ms/step\n",
      "Epoch 203/500\n",
      "7/7 - 0s - loss: 69.6584 - val_loss: 70.4957 - 44ms/epoch - 6ms/step\n",
      "Epoch 204/500\n",
      "7/7 - 0s - loss: 69.5814 - val_loss: 70.3313 - 43ms/epoch - 6ms/step\n",
      "Epoch 205/500\n",
      "7/7 - 0s - loss: 69.4464 - val_loss: 70.2528 - 43ms/epoch - 6ms/step\n",
      "Epoch 206/500\n",
      "7/7 - 0s - loss: 69.2938 - val_loss: 70.1279 - 41ms/epoch - 6ms/step\n",
      "Epoch 207/500\n",
      "7/7 - 0s - loss: 69.3572 - val_loss: 70.0094 - 42ms/epoch - 6ms/step\n",
      "Epoch 208/500\n",
      "7/7 - 0s - loss: 69.0762 - val_loss: 69.9048 - 42ms/epoch - 6ms/step\n",
      "Epoch 209/500\n",
      "7/7 - 0s - loss: 69.2045 - val_loss: 69.7592 - 41ms/epoch - 6ms/step\n",
      "Epoch 210/500\n",
      "7/7 - 0s - loss: 68.8658 - val_loss: 69.7034 - 40ms/epoch - 6ms/step\n",
      "Epoch 211/500\n",
      "7/7 - 0s - loss: 68.7845 - val_loss: 69.6361 - 47ms/epoch - 7ms/step\n",
      "Epoch 212/500\n",
      "7/7 - 0s - loss: 68.6400 - val_loss: 69.4994 - 40ms/epoch - 6ms/step\n",
      "Epoch 213/500\n",
      "7/7 - 0s - loss: 68.5174 - val_loss: 69.4178 - 40ms/epoch - 6ms/step\n",
      "Epoch 214/500\n",
      "7/7 - 0s - loss: 68.4534 - val_loss: 69.3697 - 40ms/epoch - 6ms/step\n",
      "Epoch 215/500\n",
      "7/7 - 0s - loss: 68.3994 - val_loss: 69.3129 - 41ms/epoch - 6ms/step\n",
      "Epoch 216/500\n",
      "7/7 - 0s - loss: 68.3338 - val_loss: 69.3093 - 43ms/epoch - 6ms/step\n",
      "Epoch 217/500\n",
      "7/7 - 0s - loss: 68.2147 - val_loss: 69.2619 - 40ms/epoch - 6ms/step\n",
      "Epoch 218/500\n",
      "7/7 - 0s - loss: 68.1472 - val_loss: 69.1826 - 40ms/epoch - 6ms/step\n",
      "Epoch 219/500\n",
      "7/7 - 0s - loss: 68.1745 - val_loss: 69.2425 - 42ms/epoch - 6ms/step\n",
      "Epoch 220/500\n",
      "7/7 - 0s - loss: 68.0261 - val_loss: 69.1968 - 41ms/epoch - 6ms/step\n",
      "Epoch 221/500\n",
      "7/7 - 0s - loss: 67.9596 - val_loss: 69.1136 - 43ms/epoch - 6ms/step\n",
      "Epoch 222/500\n",
      "7/7 - 0s - loss: 67.8866 - val_loss: 69.0503 - 41ms/epoch - 6ms/step\n",
      "Epoch 223/500\n",
      "7/7 - 0s - loss: 67.8216 - val_loss: 69.0686 - 40ms/epoch - 6ms/step\n",
      "Epoch 224/500\n",
      "7/7 - 0s - loss: 67.7149 - val_loss: 69.0089 - 39ms/epoch - 6ms/step\n",
      "Epoch 225/500\n",
      "7/7 - 0s - loss: 67.8340 - val_loss: 68.9597 - 40ms/epoch - 6ms/step\n",
      "Epoch 226/500\n",
      "7/7 - 0s - loss: 67.8355 - val_loss: 69.0172 - 41ms/epoch - 6ms/step\n",
      "Epoch 227/500\n",
      "7/7 - 0s - loss: 67.5960 - val_loss: 68.9373 - 41ms/epoch - 6ms/step\n",
      "Epoch 228/500\n",
      "7/7 - 0s - loss: 67.4681 - val_loss: 68.8735 - 42ms/epoch - 6ms/step\n",
      "Epoch 229/500\n",
      "7/7 - 0s - loss: 67.4368 - val_loss: 68.8455 - 41ms/epoch - 6ms/step\n",
      "Epoch 230/500\n",
      "7/7 - 0s - loss: 67.3639 - val_loss: 68.8579 - 40ms/epoch - 6ms/step\n",
      "Epoch 231/500\n",
      "7/7 - 0s - loss: 67.3491 - val_loss: 68.8212 - 40ms/epoch - 6ms/step\n",
      "Epoch 232/500\n",
      "7/7 - 0s - loss: 67.2797 - val_loss: 68.7676 - 78ms/epoch - 11ms/step\n",
      "Epoch 233/500\n",
      "7/7 - 0s - loss: 67.2579 - val_loss: 68.7230 - 46ms/epoch - 7ms/step\n",
      "Epoch 234/500\n",
      "7/7 - 0s - loss: 67.2286 - val_loss: 68.7568 - 40ms/epoch - 6ms/step\n",
      "Epoch 235/500\n",
      "7/7 - 0s - loss: 67.1112 - val_loss: 68.7792 - 41ms/epoch - 6ms/step\n",
      "Epoch 236/500\n",
      "7/7 - 0s - loss: 67.0619 - val_loss: 68.7483 - 41ms/epoch - 6ms/step\n",
      "Epoch 237/500\n",
      "7/7 - 0s - loss: 67.0218 - val_loss: 68.7194 - 41ms/epoch - 6ms/step\n",
      "Epoch 238/500\n",
      "7/7 - 0s - loss: 66.9641 - val_loss: 68.7325 - 40ms/epoch - 6ms/step\n",
      "Epoch 239/500\n",
      "7/7 - 0s - loss: 66.9259 - val_loss: 68.7404 - 42ms/epoch - 6ms/step\n",
      "Epoch 240/500\n",
      "7/7 - 0s - loss: 66.8905 - val_loss: 68.7238 - 40ms/epoch - 6ms/step\n",
      "Epoch 241/500\n",
      "7/7 - 0s - loss: 66.8661 - val_loss: 68.7237 - 42ms/epoch - 6ms/step\n",
      "Epoch 242/500\n",
      "7/7 - 0s - loss: 66.8245 - val_loss: 68.7884 - 42ms/epoch - 6ms/step\n",
      "Epoch 243/500\n",
      "7/7 - 0s - loss: 66.8063 - val_loss: 68.7189 - 41ms/epoch - 6ms/step\n",
      "Epoch 244/500\n",
      "7/7 - 0s - loss: 66.7886 - val_loss: 68.7362 - 41ms/epoch - 6ms/step\n",
      "Epoch 245/500\n",
      "7/7 - 0s - loss: 66.7271 - val_loss: 68.7146 - 42ms/epoch - 6ms/step\n",
      "Epoch 246/500\n",
      "7/7 - 0s - loss: 66.7708 - val_loss: 68.6789 - 41ms/epoch - 6ms/step\n",
      "Epoch 247/500\n",
      "7/7 - 0s - loss: 66.6401 - val_loss: 68.7116 - 42ms/epoch - 6ms/step\n",
      "Epoch 248/500\n",
      "7/7 - 0s - loss: 66.6149 - val_loss: 68.6998 - 42ms/epoch - 6ms/step\n",
      "Epoch 249/500\n",
      "7/7 - 0s - loss: 66.5660 - val_loss: 68.6762 - 40ms/epoch - 6ms/step\n",
      "Epoch 250/500\n",
      "7/7 - 0s - loss: 66.5566 - val_loss: 68.6544 - 40ms/epoch - 6ms/step\n",
      "Epoch 251/500\n",
      "7/7 - 0s - loss: 66.5410 - val_loss: 68.6974 - 39ms/epoch - 6ms/step\n",
      "Epoch 252/500\n",
      "7/7 - 0s - loss: 66.5232 - val_loss: 68.7233 - 40ms/epoch - 6ms/step\n",
      "Epoch 253/500\n",
      "7/7 - 0s - loss: 66.4588 - val_loss: 68.6721 - 40ms/epoch - 6ms/step\n",
      "Epoch 254/500\n",
      "7/7 - 0s - loss: 66.4784 - val_loss: 68.6773 - 39ms/epoch - 6ms/step\n",
      "Epoch 255/500\n",
      "7/7 - 0s - loss: 66.4181 - val_loss: 68.6921 - 53ms/epoch - 8ms/step\n",
      "Epoch 256/500\n",
      "7/7 - 0s - loss: 66.3976 - val_loss: 68.7003 - 39ms/epoch - 6ms/step\n",
      "Epoch 257/500\n",
      "7/7 - 0s - loss: 66.4091 - val_loss: 68.7028 - 38ms/epoch - 5ms/step\n",
      "Epoch 258/500\n",
      "7/7 - 0s - loss: 66.3630 - val_loss: 68.6806 - 39ms/epoch - 6ms/step\n",
      "Epoch 259/500\n",
      "7/7 - 0s - loss: 66.3677 - val_loss: 68.7023 - 39ms/epoch - 6ms/step\n",
      "Epoch 260/500\n",
      "7/7 - 0s - loss: 66.3241 - val_loss: 68.7141 - 40ms/epoch - 6ms/step\n",
      "Epoch 261/500\n",
      "7/7 - 0s - loss: 66.3010 - val_loss: 68.6979 - 38ms/epoch - 5ms/step\n",
      "Epoch 262/500\n",
      "7/7 - 0s - loss: 66.3166 - val_loss: 68.7198 - 42ms/epoch - 6ms/step\n",
      "Epoch 263/500\n",
      "7/7 - 0s - loss: 66.2708 - val_loss: 68.7383 - 42ms/epoch - 6ms/step\n",
      "Epoch 264/500\n",
      "7/7 - 0s - loss: 66.2378 - val_loss: 68.7313 - 40ms/epoch - 6ms/step\n",
      "Epoch 265/500\n",
      "7/7 - 0s - loss: 66.2262 - val_loss: 68.7192 - 41ms/epoch - 6ms/step\n",
      "Epoch 266/500\n",
      "7/7 - 0s - loss: 66.2848 - val_loss: 68.7572 - 40ms/epoch - 6ms/step\n",
      "Epoch 267/500\n",
      "7/7 - 0s - loss: 66.2578 - val_loss: 68.6815 - 62ms/epoch - 9ms/step\n",
      "Epoch 268/500\n",
      "7/7 - 0s - loss: 66.1831 - val_loss: 68.6734 - 52ms/epoch - 7ms/step\n",
      "Epoch 269/500\n",
      "7/7 - 0s - loss: 66.1818 - val_loss: 68.7412 - 39ms/epoch - 6ms/step\n",
      "Epoch 270/500\n",
      "7/7 - 0s - loss: 66.2696 - val_loss: 68.7604 - 41ms/epoch - 6ms/step\n",
      "Epoch 271/500\n",
      "7/7 - 0s - loss: 66.1673 - val_loss: 68.7349 - 38ms/epoch - 5ms/step\n",
      "Epoch 272/500\n",
      "7/7 - 0s - loss: 66.2139 - val_loss: 68.7570 - 41ms/epoch - 6ms/step\n",
      "Epoch 273/500\n",
      "7/7 - 0s - loss: 66.1111 - val_loss: 68.7163 - 38ms/epoch - 5ms/step\n",
      "Epoch 274/500\n",
      "7/7 - 0s - loss: 66.0686 - val_loss: 68.6909 - 39ms/epoch - 6ms/step\n",
      "Epoch 275/500\n",
      "7/7 - 0s - loss: 66.0473 - val_loss: 68.6626 - 42ms/epoch - 6ms/step\n",
      "Epoch 276/500\n",
      "7/7 - 0s - loss: 66.0312 - val_loss: 68.6498 - 39ms/epoch - 6ms/step\n",
      "Epoch 277/500\n",
      "7/7 - 0s - loss: 65.9697 - val_loss: 68.6726 - 43ms/epoch - 6ms/step\n",
      "Epoch 278/500\n",
      "7/7 - 0s - loss: 65.9607 - val_loss: 68.6826 - 39ms/epoch - 6ms/step\n",
      "Epoch 279/500\n",
      "7/7 - 0s - loss: 65.9527 - val_loss: 68.7031 - 40ms/epoch - 6ms/step\n",
      "Epoch 280/500\n",
      "7/7 - 0s - loss: 65.9727 - val_loss: 68.7367 - 38ms/epoch - 5ms/step\n",
      "Epoch 281/500\n",
      "7/7 - 0s - loss: 65.9279 - val_loss: 68.7038 - 39ms/epoch - 6ms/step\n",
      "Epoch 282/500\n",
      "7/7 - 0s - loss: 65.8942 - val_loss: 68.7184 - 40ms/epoch - 6ms/step\n",
      "Epoch 283/500\n",
      "7/7 - 0s - loss: 65.8582 - val_loss: 68.7041 - 38ms/epoch - 5ms/step\n",
      "Epoch 284/500\n",
      "7/7 - 0s - loss: 65.8770 - val_loss: 68.7163 - 40ms/epoch - 6ms/step\n",
      "Epoch 285/500\n",
      "7/7 - 0s - loss: 65.8529 - val_loss: 68.6857 - 39ms/epoch - 6ms/step\n",
      "Epoch 286/500\n",
      "7/7 - 0s - loss: 65.8872 - val_loss: 68.6882 - 40ms/epoch - 6ms/step\n",
      "Epoch 287/500\n",
      "7/7 - 0s - loss: 65.7791 - val_loss: 68.6868 - 39ms/epoch - 6ms/step\n",
      "Epoch 288/500\n",
      "7/7 - 0s - loss: 65.8342 - val_loss: 68.6459 - 39ms/epoch - 6ms/step\n",
      "Epoch 289/500\n",
      "7/7 - 0s - loss: 65.8589 - val_loss: 68.6587 - 40ms/epoch - 6ms/step\n",
      "Epoch 290/500\n",
      "7/7 - 0s - loss: 65.7701 - val_loss: 68.6896 - 39ms/epoch - 6ms/step\n",
      "Epoch 291/500\n",
      "7/7 - 0s - loss: 65.7277 - val_loss: 68.6874 - 39ms/epoch - 6ms/step\n",
      "Epoch 292/500\n",
      "7/7 - 0s - loss: 65.7169 - val_loss: 68.6905 - 41ms/epoch - 6ms/step\n",
      "Epoch 293/500\n",
      "7/7 - 0s - loss: 65.7033 - val_loss: 68.6734 - 44ms/epoch - 6ms/step\n",
      "Epoch 294/500\n",
      "7/7 - 0s - loss: 65.7148 - val_loss: 68.7342 - 42ms/epoch - 6ms/step\n",
      "Epoch 295/500\n",
      "7/7 - 0s - loss: 65.6830 - val_loss: 68.7243 - 39ms/epoch - 6ms/step\n",
      "Epoch 296/500\n",
      "7/7 - 0s - loss: 65.6511 - val_loss: 68.7061 - 38ms/epoch - 5ms/step\n",
      "Epoch 297/500\n",
      "7/7 - 0s - loss: 65.6801 - val_loss: 68.7264 - 41ms/epoch - 6ms/step\n",
      "Epoch 298/500\n",
      "7/7 - 0s - loss: 65.6306 - val_loss: 68.7066 - 39ms/epoch - 6ms/step\n",
      "Epoch 299/500\n",
      "7/7 - 0s - loss: 65.6338 - val_loss: 68.7116 - 39ms/epoch - 6ms/step\n",
      "Epoch 300/500\n",
      "7/7 - 0s - loss: 65.5995 - val_loss: 68.6825 - 39ms/epoch - 6ms/step\n",
      "Epoch 301/500\n",
      "7/7 - 0s - loss: 65.5841 - val_loss: 68.6823 - 39ms/epoch - 6ms/step\n",
      "Epoch 302/500\n",
      "7/7 - 0s - loss: 65.5588 - val_loss: 68.7252 - 40ms/epoch - 6ms/step\n",
      "Epoch 303/500\n",
      "7/7 - 0s - loss: 65.5643 - val_loss: 68.7468 - 41ms/epoch - 6ms/step\n",
      "Epoch 304/500\n",
      "7/7 - 0s - loss: 65.5297 - val_loss: 68.7090 - 78ms/epoch - 11ms/step\n",
      "Epoch 305/500\n",
      "7/7 - 0s - loss: 65.5350 - val_loss: 68.7161 - 44ms/epoch - 6ms/step\n",
      "Epoch 306/500\n",
      "7/7 - 0s - loss: 65.5280 - val_loss: 68.7539 - 40ms/epoch - 6ms/step\n",
      "Epoch 307/500\n",
      "7/7 - 0s - loss: 65.4763 - val_loss: 68.7385 - 38ms/epoch - 5ms/step\n",
      "Epoch 308/500\n",
      "7/7 - 0s - loss: 65.4933 - val_loss: 68.7328 - 40ms/epoch - 6ms/step\n",
      "Epoch 309/500\n",
      "7/7 - 0s - loss: 65.4489 - val_loss: 68.7108 - 41ms/epoch - 6ms/step\n",
      "Epoch 310/500\n",
      "7/7 - 0s - loss: 65.4329 - val_loss: 68.7337 - 39ms/epoch - 6ms/step\n",
      "Epoch 311/500\n",
      "7/7 - 0s - loss: 65.4354 - val_loss: 68.7145 - 39ms/epoch - 6ms/step\n",
      "Epoch 312/500\n",
      "7/7 - 0s - loss: 65.4163 - val_loss: 68.7447 - 38ms/epoch - 5ms/step\n",
      "Epoch 313/500\n",
      "7/7 - 0s - loss: 65.4361 - val_loss: 68.7178 - 40ms/epoch - 6ms/step\n",
      "Epoch 314/500\n",
      "7/7 - 0s - loss: 65.3934 - val_loss: 68.7053 - 40ms/epoch - 6ms/step\n",
      "Epoch 315/500\n",
      "7/7 - 0s - loss: 65.4042 - val_loss: 68.7008 - 41ms/epoch - 6ms/step\n",
      "Epoch 316/500\n",
      "7/7 - 0s - loss: 65.4001 - val_loss: 68.7305 - 40ms/epoch - 6ms/step\n",
      "Epoch 317/500\n",
      "7/7 - 0s - loss: 65.3338 - val_loss: 68.6989 - 40ms/epoch - 6ms/step\n",
      "Epoch 318/500\n",
      "7/7 - 0s - loss: 65.3418 - val_loss: 68.7335 - 38ms/epoch - 5ms/step\n",
      "Epoch 319/500\n",
      "7/7 - 0s - loss: 65.3897 - val_loss: 68.7672 - 39ms/epoch - 6ms/step\n",
      "Epoch 320/500\n",
      "7/7 - 0s - loss: 65.2936 - val_loss: 68.7105 - 39ms/epoch - 6ms/step\n",
      "Epoch 321/500\n",
      "7/7 - 0s - loss: 65.3146 - val_loss: 68.6582 - 39ms/epoch - 6ms/step\n",
      "Epoch 322/500\n",
      "7/7 - 0s - loss: 65.2550 - val_loss: 68.6752 - 65ms/epoch - 9ms/step\n",
      "Epoch 323/500\n",
      "7/7 - 0s - loss: 65.2599 - val_loss: 68.6935 - 39ms/epoch - 6ms/step\n",
      "Epoch 324/500\n",
      "7/7 - 0s - loss: 65.2575 - val_loss: 68.6899 - 39ms/epoch - 6ms/step\n",
      "Epoch 325/500\n",
      "7/7 - 0s - loss: 65.2292 - val_loss: 68.6961 - 39ms/epoch - 6ms/step\n",
      "Epoch 326/500\n",
      "7/7 - 0s - loss: 65.2633 - val_loss: 68.7144 - 45ms/epoch - 6ms/step\n",
      "Epoch 327/500\n",
      "7/7 - 0s - loss: 65.1810 - val_loss: 68.6756 - 48ms/epoch - 7ms/step\n",
      "Epoch 328/500\n",
      "7/7 - 0s - loss: 65.2232 - val_loss: 68.6410 - 75ms/epoch - 11ms/step\n",
      "Epoch 329/500\n",
      "7/7 - 0s - loss: 65.1651 - val_loss: 68.6197 - 45ms/epoch - 6ms/step\n",
      "Epoch 330/500\n",
      "7/7 - 0s - loss: 65.1857 - val_loss: 68.6175 - 37ms/epoch - 5ms/step\n",
      "Epoch 331/500\n",
      "7/7 - 0s - loss: 65.1353 - val_loss: 68.6152 - 38ms/epoch - 5ms/step\n",
      "Epoch 332/500\n",
      "7/7 - 0s - loss: 65.1261 - val_loss: 68.6155 - 40ms/epoch - 6ms/step\n",
      "Epoch 333/500\n",
      "7/7 - 0s - loss: 65.1030 - val_loss: 68.5805 - 41ms/epoch - 6ms/step\n",
      "Epoch 334/500\n",
      "7/7 - 0s - loss: 65.1069 - val_loss: 68.5538 - 39ms/epoch - 6ms/step\n",
      "Epoch 335/500\n",
      "7/7 - 0s - loss: 65.0652 - val_loss: 68.5555 - 47ms/epoch - 7ms/step\n",
      "Epoch 336/500\n",
      "7/7 - 0s - loss: 65.2629 - val_loss: 68.5591 - 73ms/epoch - 10ms/step\n",
      "Epoch 337/500\n",
      "7/7 - 0s - loss: 65.0368 - val_loss: 68.5216 - 43ms/epoch - 6ms/step\n",
      "Epoch 338/500\n",
      "7/7 - 0s - loss: 65.1505 - val_loss: 68.5325 - 42ms/epoch - 6ms/step\n",
      "Epoch 339/500\n",
      "7/7 - 0s - loss: 65.1344 - val_loss: 68.5212 - 41ms/epoch - 6ms/step\n",
      "Epoch 340/500\n",
      "7/7 - 0s - loss: 65.0203 - val_loss: 68.5427 - 39ms/epoch - 6ms/step\n",
      "Epoch 341/500\n",
      "7/7 - 0s - loss: 65.0267 - val_loss: 68.5513 - 40ms/epoch - 6ms/step\n",
      "Epoch 342/500\n",
      "7/7 - 0s - loss: 65.1197 - val_loss: 68.5448 - 41ms/epoch - 6ms/step\n",
      "Epoch 343/500\n",
      "7/7 - 0s - loss: 65.0484 - val_loss: 68.5133 - 41ms/epoch - 6ms/step\n",
      "Epoch 344/500\n",
      "7/7 - 0s - loss: 64.9774 - val_loss: 68.4831 - 43ms/epoch - 6ms/step\n",
      "Epoch 345/500\n",
      "7/7 - 0s - loss: 64.9807 - val_loss: 68.4988 - 40ms/epoch - 6ms/step\n",
      "Epoch 346/500\n",
      "7/7 - 0s - loss: 64.9572 - val_loss: 68.4830 - 41ms/epoch - 6ms/step\n",
      "Epoch 347/500\n",
      "7/7 - 0s - loss: 64.9811 - val_loss: 68.4576 - 39ms/epoch - 6ms/step\n",
      "Epoch 348/500\n",
      "7/7 - 0s - loss: 64.9807 - val_loss: 68.4771 - 41ms/epoch - 6ms/step\n",
      "Epoch 349/500\n",
      "7/7 - 0s - loss: 64.9518 - val_loss: 68.3943 - 39ms/epoch - 6ms/step\n",
      "Epoch 350/500\n",
      "7/7 - 0s - loss: 64.9092 - val_loss: 68.4008 - 40ms/epoch - 6ms/step\n",
      "Epoch 351/500\n",
      "7/7 - 0s - loss: 64.9423 - val_loss: 68.4282 - 40ms/epoch - 6ms/step\n",
      "Epoch 352/500\n",
      "7/7 - 0s - loss: 64.8617 - val_loss: 68.4081 - 40ms/epoch - 6ms/step\n",
      "Epoch 353/500\n",
      "7/7 - 0s - loss: 64.8883 - val_loss: 68.4103 - 39ms/epoch - 6ms/step\n",
      "Epoch 354/500\n",
      "7/7 - 0s - loss: 64.8509 - val_loss: 68.3922 - 40ms/epoch - 6ms/step\n",
      "Epoch 355/500\n",
      "7/7 - 0s - loss: 64.8502 - val_loss: 68.3448 - 40ms/epoch - 6ms/step\n",
      "Epoch 356/500\n",
      "7/7 - 0s - loss: 64.8693 - val_loss: 68.3767 - 38ms/epoch - 5ms/step\n",
      "Epoch 357/500\n",
      "7/7 - 0s - loss: 64.8670 - val_loss: 68.3202 - 40ms/epoch - 6ms/step\n",
      "Epoch 358/500\n",
      "7/7 - 0s - loss: 64.7985 - val_loss: 68.3325 - 40ms/epoch - 6ms/step\n",
      "Epoch 359/500\n",
      "7/7 - 0s - loss: 64.7955 - val_loss: 68.3083 - 40ms/epoch - 6ms/step\n",
      "Epoch 360/500\n",
      "7/7 - 0s - loss: 64.8025 - val_loss: 68.2373 - 40ms/epoch - 6ms/step\n",
      "Epoch 361/500\n",
      "7/7 - 0s - loss: 64.7634 - val_loss: 68.2881 - 39ms/epoch - 6ms/step\n",
      "Epoch 362/500\n",
      "7/7 - 0s - loss: 64.7465 - val_loss: 68.2917 - 40ms/epoch - 6ms/step\n",
      "Epoch 363/500\n",
      "7/7 - 0s - loss: 64.7457 - val_loss: 68.2701 - 39ms/epoch - 6ms/step\n",
      "Epoch 364/500\n",
      "7/7 - 0s - loss: 64.8247 - val_loss: 68.2891 - 39ms/epoch - 6ms/step\n",
      "Epoch 365/500\n",
      "7/7 - 0s - loss: 64.7150 - val_loss: 68.2886 - 40ms/epoch - 6ms/step\n",
      "Epoch 366/500\n",
      "7/7 - 0s - loss: 64.7117 - val_loss: 68.2895 - 43ms/epoch - 6ms/step\n",
      "Epoch 367/500\n",
      "7/7 - 0s - loss: 64.7304 - val_loss: 68.2872 - 39ms/epoch - 6ms/step\n",
      "Epoch 368/500\n",
      "7/7 - 0s - loss: 64.6745 - val_loss: 68.2414 - 40ms/epoch - 6ms/step\n",
      "Epoch 369/500\n",
      "7/7 - 0s - loss: 64.6738 - val_loss: 68.2029 - 81ms/epoch - 12ms/step\n",
      "Epoch 370/500\n",
      "7/7 - 0s - loss: 64.6730 - val_loss: 68.2222 - 42ms/epoch - 6ms/step\n",
      "Epoch 371/500\n",
      "7/7 - 0s - loss: 64.6218 - val_loss: 68.2052 - 39ms/epoch - 6ms/step\n",
      "Epoch 372/500\n",
      "7/7 - 0s - loss: 64.7090 - val_loss: 68.2426 - 39ms/epoch - 6ms/step\n",
      "Epoch 373/500\n",
      "7/7 - 0s - loss: 64.6588 - val_loss: 68.2290 - 41ms/epoch - 6ms/step\n",
      "Epoch 374/500\n",
      "7/7 - 0s - loss: 64.6362 - val_loss: 68.1454 - 40ms/epoch - 6ms/step\n",
      "Epoch 375/500\n",
      "7/7 - 0s - loss: 64.6067 - val_loss: 68.1254 - 40ms/epoch - 6ms/step\n",
      "Epoch 376/500\n",
      "7/7 - 0s - loss: 64.5757 - val_loss: 68.1099 - 39ms/epoch - 6ms/step\n",
      "Epoch 377/500\n",
      "7/7 - 0s - loss: 64.5633 - val_loss: 68.1164 - 39ms/epoch - 6ms/step\n",
      "Epoch 378/500\n",
      "7/7 - 0s - loss: 64.5601 - val_loss: 68.1306 - 40ms/epoch - 6ms/step\n",
      "Epoch 379/500\n",
      "7/7 - 0s - loss: 64.5700 - val_loss: 68.0769 - 63ms/epoch - 9ms/step\n",
      "Epoch 380/500\n",
      "7/7 - 0s - loss: 64.5292 - val_loss: 68.1061 - 41ms/epoch - 6ms/step\n",
      "Epoch 381/500\n",
      "7/7 - 0s - loss: 64.5220 - val_loss: 68.0788 - 39ms/epoch - 6ms/step\n",
      "Epoch 382/500\n",
      "7/7 - 0s - loss: 64.5535 - val_loss: 68.0550 - 38ms/epoch - 5ms/step\n",
      "Epoch 383/500\n",
      "7/7 - 0s - loss: 64.5075 - val_loss: 68.0822 - 40ms/epoch - 6ms/step\n",
      "Epoch 384/500\n",
      "7/7 - 0s - loss: 64.5054 - val_loss: 68.0461 - 39ms/epoch - 6ms/step\n",
      "Epoch 385/500\n",
      "7/7 - 0s - loss: 64.4848 - val_loss: 68.0576 - 40ms/epoch - 6ms/step\n",
      "Epoch 386/500\n",
      "7/7 - 0s - loss: 64.5460 - val_loss: 68.0769 - 39ms/epoch - 6ms/step\n",
      "Epoch 387/500\n",
      "7/7 - 0s - loss: 64.4396 - val_loss: 68.0625 - 40ms/epoch - 6ms/step\n",
      "Epoch 388/500\n",
      "7/7 - 0s - loss: 64.4757 - val_loss: 68.0603 - 40ms/epoch - 6ms/step\n",
      "Epoch 389/500\n",
      "7/7 - 0s - loss: 64.4157 - val_loss: 67.9941 - 41ms/epoch - 6ms/step\n",
      "Epoch 390/500\n",
      "7/7 - 0s - loss: 64.4839 - val_loss: 67.9814 - 40ms/epoch - 6ms/step\n",
      "Epoch 391/500\n",
      "7/7 - 0s - loss: 64.4082 - val_loss: 67.9985 - 41ms/epoch - 6ms/step\n",
      "Epoch 392/500\n",
      "7/7 - 0s - loss: 64.4543 - val_loss: 67.9804 - 39ms/epoch - 6ms/step\n",
      "Epoch 393/500\n",
      "7/7 - 0s - loss: 64.3783 - val_loss: 67.9569 - 40ms/epoch - 6ms/step\n",
      "Epoch 394/500\n",
      "7/7 - 0s - loss: 64.4014 - val_loss: 68.0088 - 39ms/epoch - 6ms/step\n",
      "Epoch 395/500\n",
      "7/7 - 0s - loss: 64.3700 - val_loss: 67.9782 - 40ms/epoch - 6ms/step\n",
      "Epoch 396/500\n",
      "7/7 - 0s - loss: 64.3430 - val_loss: 67.9348 - 38ms/epoch - 5ms/step\n",
      "Epoch 397/500\n",
      "7/7 - 0s - loss: 64.3817 - val_loss: 67.9699 - 42ms/epoch - 6ms/step\n",
      "Epoch 398/500\n",
      "7/7 - 0s - loss: 64.3386 - val_loss: 67.9048 - 39ms/epoch - 6ms/step\n",
      "Epoch 399/500\n",
      "7/7 - 0s - loss: 64.3369 - val_loss: 67.8766 - 82ms/epoch - 12ms/step\n",
      "Epoch 400/500\n",
      "7/7 - 0s - loss: 64.2958 - val_loss: 67.8280 - 43ms/epoch - 6ms/step\n",
      "Epoch 401/500\n",
      "7/7 - 0s - loss: 64.2649 - val_loss: 67.8061 - 41ms/epoch - 6ms/step\n",
      "Epoch 402/500\n",
      "7/7 - 0s - loss: 64.2735 - val_loss: 67.8131 - 40ms/epoch - 6ms/step\n",
      "Epoch 403/500\n",
      "7/7 - 0s - loss: 64.2606 - val_loss: 67.8132 - 40ms/epoch - 6ms/step\n",
      "Epoch 404/500\n",
      "7/7 - 0s - loss: 64.2641 - val_loss: 67.8294 - 40ms/epoch - 6ms/step\n",
      "Epoch 405/500\n",
      "7/7 - 0s - loss: 64.2623 - val_loss: 67.8110 - 39ms/epoch - 6ms/step\n",
      "Epoch 406/500\n",
      "7/7 - 0s - loss: 64.2569 - val_loss: 67.8026 - 40ms/epoch - 6ms/step\n",
      "Epoch 407/500\n",
      "7/7 - 0s - loss: 64.2041 - val_loss: 67.7851 - 39ms/epoch - 6ms/step\n",
      "Epoch 408/500\n",
      "7/7 - 0s - loss: 64.1824 - val_loss: 67.7432 - 41ms/epoch - 6ms/step\n",
      "Epoch 409/500\n",
      "7/7 - 0s - loss: 64.2025 - val_loss: 67.7025 - 40ms/epoch - 6ms/step\n",
      "Epoch 410/500\n",
      "7/7 - 0s - loss: 64.1842 - val_loss: 67.7125 - 40ms/epoch - 6ms/step\n",
      "Epoch 411/500\n",
      "7/7 - 0s - loss: 64.1491 - val_loss: 67.7096 - 43ms/epoch - 6ms/step\n",
      "Epoch 412/500\n",
      "7/7 - 0s - loss: 64.1690 - val_loss: 67.7349 - 40ms/epoch - 6ms/step\n",
      "Epoch 413/500\n",
      "7/7 - 0s - loss: 64.1103 - val_loss: 67.6773 - 42ms/epoch - 6ms/step\n",
      "Epoch 414/500\n",
      "7/7 - 0s - loss: 64.2251 - val_loss: 67.6711 - 39ms/epoch - 6ms/step\n",
      "Epoch 415/500\n",
      "7/7 - 0s - loss: 64.0911 - val_loss: 67.6920 - 40ms/epoch - 6ms/step\n",
      "Epoch 416/500\n",
      "7/7 - 0s - loss: 64.2990 - val_loss: 67.6452 - 39ms/epoch - 6ms/step\n",
      "Epoch 417/500\n",
      "7/7 - 0s - loss: 64.1462 - val_loss: 67.6962 - 39ms/epoch - 6ms/step\n",
      "Epoch 418/500\n",
      "7/7 - 0s - loss: 64.6870 - val_loss: 67.7402 - 41ms/epoch - 6ms/step\n",
      "Epoch 419/500\n",
      "7/7 - 0s - loss: 64.4228 - val_loss: 67.6477 - 39ms/epoch - 6ms/step\n",
      "Epoch 420/500\n",
      "7/7 - 0s - loss: 64.0782 - val_loss: 67.6158 - 41ms/epoch - 6ms/step\n",
      "Epoch 421/500\n",
      "7/7 - 0s - loss: 64.2470 - val_loss: 67.6947 - 38ms/epoch - 5ms/step\n",
      "Epoch 422/500\n",
      "7/7 - 0s - loss: 64.0453 - val_loss: 67.6527 - 40ms/epoch - 6ms/step\n",
      "Epoch 423/500\n",
      "7/7 - 0s - loss: 64.1498 - val_loss: 67.6293 - 39ms/epoch - 6ms/step\n",
      "Epoch 424/500\n",
      "7/7 - 0s - loss: 64.0112 - val_loss: 67.5446 - 42ms/epoch - 6ms/step\n",
      "Epoch 425/500\n",
      "7/7 - 0s - loss: 63.9952 - val_loss: 67.5384 - 43ms/epoch - 6ms/step\n",
      "Epoch 426/500\n",
      "7/7 - 0s - loss: 63.9931 - val_loss: 67.5363 - 39ms/epoch - 6ms/step\n",
      "Epoch 427/500\n",
      "7/7 - 0s - loss: 64.0099 - val_loss: 67.5337 - 39ms/epoch - 6ms/step\n",
      "Epoch 428/500\n",
      "7/7 - 0s - loss: 63.9550 - val_loss: 67.5382 - 40ms/epoch - 6ms/step\n",
      "Epoch 429/500\n",
      "7/7 - 0s - loss: 63.9566 - val_loss: 67.4771 - 61ms/epoch - 9ms/step\n",
      "Epoch 430/500\n",
      "7/7 - 0s - loss: 63.9651 - val_loss: 67.4385 - 84ms/epoch - 12ms/step\n",
      "Epoch 431/500\n",
      "7/7 - 0s - loss: 63.9321 - val_loss: 67.4688 - 41ms/epoch - 6ms/step\n",
      "Epoch 432/500\n",
      "7/7 - 0s - loss: 63.9356 - val_loss: 67.4704 - 38ms/epoch - 5ms/step\n",
      "Epoch 433/500\n",
      "7/7 - 0s - loss: 63.9148 - val_loss: 67.4358 - 41ms/epoch - 6ms/step\n",
      "Epoch 434/500\n",
      "7/7 - 0s - loss: 63.8955 - val_loss: 67.4580 - 38ms/epoch - 5ms/step\n",
      "Epoch 435/500\n",
      "7/7 - 0s - loss: 63.9044 - val_loss: 67.4086 - 40ms/epoch - 6ms/step\n",
      "Epoch 436/500\n",
      "7/7 - 0s - loss: 63.8970 - val_loss: 67.4785 - 40ms/epoch - 6ms/step\n",
      "Epoch 437/500\n",
      "7/7 - 0s - loss: 63.8439 - val_loss: 67.3958 - 41ms/epoch - 6ms/step\n",
      "Epoch 438/500\n",
      "7/7 - 0s - loss: 63.9014 - val_loss: 67.3615 - 41ms/epoch - 6ms/step\n",
      "Epoch 439/500\n",
      "7/7 - 0s - loss: 63.8283 - val_loss: 67.3141 - 40ms/epoch - 6ms/step\n",
      "Epoch 440/500\n",
      "7/7 - 0s - loss: 63.8207 - val_loss: 67.3470 - 40ms/epoch - 6ms/step\n",
      "Epoch 441/500\n",
      "7/7 - 0s - loss: 63.8699 - val_loss: 67.3517 - 38ms/epoch - 5ms/step\n",
      "Epoch 442/500\n",
      "7/7 - 0s - loss: 63.8031 - val_loss: 67.3315 - 41ms/epoch - 6ms/step\n",
      "Epoch 443/500\n",
      "7/7 - 0s - loss: 63.8380 - val_loss: 67.3138 - 40ms/epoch - 6ms/step\n",
      "Epoch 444/500\n",
      "7/7 - 0s - loss: 63.7811 - val_loss: 67.3442 - 39ms/epoch - 6ms/step\n",
      "Epoch 445/500\n",
      "7/7 - 0s - loss: 63.7727 - val_loss: 67.2859 - 39ms/epoch - 6ms/step\n",
      "Epoch 446/500\n",
      "7/7 - 0s - loss: 63.7353 - val_loss: 67.2971 - 40ms/epoch - 6ms/step\n",
      "Epoch 447/500\n",
      "7/7 - 0s - loss: 63.7820 - val_loss: 67.3085 - 39ms/epoch - 6ms/step\n",
      "Epoch 448/500\n",
      "7/7 - 0s - loss: 63.9078 - val_loss: 67.2871 - 41ms/epoch - 6ms/step\n",
      "Epoch 449/500\n",
      "7/7 - 0s - loss: 63.9475 - val_loss: 67.2216 - 41ms/epoch - 6ms/step\n",
      "Epoch 450/500\n",
      "7/7 - 0s - loss: 63.7119 - val_loss: 67.2628 - 39ms/epoch - 6ms/step\n",
      "Epoch 451/500\n",
      "7/7 - 0s - loss: 63.6742 - val_loss: 67.2041 - 41ms/epoch - 6ms/step\n",
      "Epoch 452/500\n",
      "7/7 - 0s - loss: 63.6838 - val_loss: 67.1578 - 38ms/epoch - 5ms/step\n",
      "Epoch 453/500\n",
      "7/7 - 0s - loss: 63.6593 - val_loss: 67.1760 - 41ms/epoch - 6ms/step\n",
      "Epoch 454/500\n",
      "7/7 - 0s - loss: 63.6208 - val_loss: 67.1474 - 39ms/epoch - 6ms/step\n",
      "Epoch 455/500\n",
      "7/7 - 0s - loss: 63.6424 - val_loss: 67.1646 - 40ms/epoch - 6ms/step\n",
      "Epoch 456/500\n",
      "7/7 - 0s - loss: 63.5958 - val_loss: 67.1668 - 39ms/epoch - 6ms/step\n",
      "Epoch 457/500\n",
      "7/7 - 0s - loss: 63.5801 - val_loss: 67.1253 - 40ms/epoch - 6ms/step\n",
      "Epoch 458/500\n",
      "7/7 - 0s - loss: 63.6003 - val_loss: 67.1033 - 40ms/epoch - 6ms/step\n",
      "Epoch 459/500\n",
      "7/7 - 0s - loss: 63.5692 - val_loss: 67.0648 - 66ms/epoch - 9ms/step\n",
      "Epoch 460/500\n",
      "7/7 - 0s - loss: 63.5504 - val_loss: 67.0526 - 48ms/epoch - 7ms/step\n",
      "Epoch 461/500\n",
      "7/7 - 0s - loss: 63.5366 - val_loss: 67.0337 - 41ms/epoch - 6ms/step\n",
      "Epoch 462/500\n",
      "7/7 - 0s - loss: 63.5717 - val_loss: 67.0576 - 38ms/epoch - 5ms/step\n",
      "Epoch 463/500\n",
      "7/7 - 0s - loss: 63.5276 - val_loss: 67.0136 - 38ms/epoch - 5ms/step\n",
      "Epoch 464/500\n",
      "7/7 - 0s - loss: 63.5039 - val_loss: 67.0508 - 40ms/epoch - 6ms/step\n",
      "Epoch 465/500\n",
      "7/7 - 0s - loss: 63.4958 - val_loss: 67.0234 - 39ms/epoch - 6ms/step\n",
      "Epoch 466/500\n",
      "7/7 - 0s - loss: 63.5153 - val_loss: 66.9989 - 38ms/epoch - 5ms/step\n",
      "Epoch 467/500\n",
      "7/7 - 0s - loss: 63.4612 - val_loss: 66.9800 - 43ms/epoch - 6ms/step\n",
      "Epoch 468/500\n",
      "7/7 - 0s - loss: 63.4641 - val_loss: 66.9305 - 40ms/epoch - 6ms/step\n",
      "Epoch 469/500\n",
      "7/7 - 0s - loss: 63.4720 - val_loss: 66.9549 - 40ms/epoch - 6ms/step\n",
      "Epoch 470/500\n",
      "7/7 - 0s - loss: 63.4823 - val_loss: 66.9446 - 42ms/epoch - 6ms/step\n",
      "Epoch 471/500\n",
      "7/7 - 0s - loss: 63.4050 - val_loss: 66.9397 - 40ms/epoch - 6ms/step\n",
      "Epoch 472/500\n",
      "7/7 - 0s - loss: 63.4739 - val_loss: 66.8753 - 40ms/epoch - 6ms/step\n",
      "Epoch 473/500\n",
      "7/7 - 0s - loss: 63.4369 - val_loss: 66.8895 - 56ms/epoch - 8ms/step\n",
      "Epoch 474/500\n",
      "7/7 - 0s - loss: 63.5650 - val_loss: 66.8576 - 44ms/epoch - 6ms/step\n",
      "Epoch 475/500\n",
      "7/7 - 0s - loss: 63.3770 - val_loss: 66.7761 - 40ms/epoch - 6ms/step\n",
      "Epoch 476/500\n",
      "7/7 - 0s - loss: 63.6094 - val_loss: 66.8606 - 39ms/epoch - 6ms/step\n",
      "Epoch 477/500\n",
      "7/7 - 0s - loss: 63.5199 - val_loss: 66.8821 - 39ms/epoch - 6ms/step\n",
      "Epoch 478/500\n",
      "7/7 - 0s - loss: 63.3357 - val_loss: 66.7796 - 43ms/epoch - 6ms/step\n",
      "Epoch 479/500\n",
      "7/7 - 0s - loss: 63.5779 - val_loss: 66.8048 - 41ms/epoch - 6ms/step\n",
      "Epoch 480/500\n",
      "7/7 - 0s - loss: 63.3704 - val_loss: 66.7643 - 40ms/epoch - 6ms/step\n",
      "Epoch 481/500\n",
      "7/7 - 0s - loss: 63.3030 - val_loss: 66.7489 - 39ms/epoch - 6ms/step\n",
      "Epoch 482/500\n",
      "7/7 - 0s - loss: 63.2655 - val_loss: 66.7252 - 40ms/epoch - 6ms/step\n",
      "Epoch 483/500\n",
      "7/7 - 0s - loss: 63.2912 - val_loss: 66.6964 - 39ms/epoch - 6ms/step\n",
      "Epoch 484/500\n",
      "7/7 - 0s - loss: 63.2860 - val_loss: 66.7179 - 40ms/epoch - 6ms/step\n",
      "Epoch 485/500\n",
      "7/7 - 0s - loss: 63.2627 - val_loss: 66.6852 - 40ms/epoch - 6ms/step\n",
      "Epoch 486/500\n",
      "7/7 - 0s - loss: 63.2446 - val_loss: 66.6426 - 40ms/epoch - 6ms/step\n",
      "Epoch 487/500\n",
      "7/7 - 0s - loss: 63.2318 - val_loss: 66.6726 - 38ms/epoch - 5ms/step\n",
      "Epoch 488/500\n",
      "7/7 - 0s - loss: 63.2383 - val_loss: 66.6156 - 41ms/epoch - 6ms/step\n",
      "Epoch 489/500\n",
      "7/7 - 0s - loss: 63.1917 - val_loss: 66.6094 - 75ms/epoch - 11ms/step\n",
      "Epoch 490/500\n",
      "7/7 - 0s - loss: 63.2262 - val_loss: 66.6702 - 41ms/epoch - 6ms/step\n",
      "Epoch 491/500\n",
      "7/7 - 0s - loss: 63.2005 - val_loss: 66.6503 - 39ms/epoch - 6ms/step\n",
      "Epoch 492/500\n",
      "7/7 - 0s - loss: 63.1606 - val_loss: 66.5631 - 38ms/epoch - 5ms/step\n",
      "Epoch 493/500\n",
      "7/7 - 0s - loss: 63.2383 - val_loss: 66.5561 - 41ms/epoch - 6ms/step\n",
      "Epoch 494/500\n",
      "7/7 - 0s - loss: 63.1627 - val_loss: 66.5821 - 39ms/epoch - 6ms/step\n",
      "Epoch 495/500\n",
      "7/7 - 0s - loss: 63.1495 - val_loss: 66.5125 - 41ms/epoch - 6ms/step\n",
      "Epoch 496/500\n",
      "7/7 - 0s - loss: 63.1355 - val_loss: 66.5227 - 39ms/epoch - 6ms/step\n",
      "Epoch 497/500\n",
      "7/7 - 0s - loss: 63.0670 - val_loss: 66.5232 - 39ms/epoch - 6ms/step\n",
      "Epoch 498/500\n",
      "7/7 - 0s - loss: 63.0968 - val_loss: 66.4770 - 40ms/epoch - 6ms/step\n",
      "Epoch 499/500\n",
      "7/7 - 0s - loss: 63.0661 - val_loss: 66.4742 - 39ms/epoch - 6ms/step\n",
      "Epoch 500/500\n",
      "7/7 - 0s - loss: 63.1012 - val_loss: 66.4726 - 40ms/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu', input_shape = input_shape))\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_squared_error')\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=500, verbose=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 66.4726\n",
      "Erro no conjunto de teste: 66.47260284423828\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Valor Real: 7, PrevisÃ£o: 16.921913146972656\n",
      "Valor Real: 16, PrevisÃ£o: 17.379411697387695\n",
      "Valor Real: 25, PrevisÃ£o: 19.32094955444336\n",
      "Valor Real: 32, PrevisÃ£o: 18.27483367919922\n",
      "Valor Real: 6, PrevisÃ£o: 16.83615493774414\n",
      "Valor Real: 17, PrevisÃ£o: 19.153921127319336\n",
      "Valor Real: 13, PrevisÃ£o: 16.909442901611328\n",
      "Valor Real: 4, PrevisÃ£o: 13.679250717163086\n",
      "Valor Real: 18, PrevisÃ£o: 16.434341430664062\n",
      "Valor Real: 10, PrevisÃ£o: 19.1240177154541\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Erro no conjunto de teste: {loss}')\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'Valor Real: {y_test[i]}, PrevisÃ£o: {predictions[i][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 3.4786 - accuracy: 0.0352 - val_loss: 3.4545 - val_accuracy: 0.0469\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4699 - accuracy: 0.0469 - val_loss: 3.4557 - val_accuracy: 0.0469\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4702 - accuracy: 0.0312 - val_loss: 3.4569 - val_accuracy: 0.0469\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.4663 - accuracy: 0.0234 - val_loss: 3.4579 - val_accuracy: 0.0469\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4692 - accuracy: 0.0234 - val_loss: 3.4587 - val_accuracy: 0.0469\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4721 - accuracy: 0.0312 - val_loss: 3.4593 - val_accuracy: 0.0469\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4712 - accuracy: 0.0273 - val_loss: 3.4598 - val_accuracy: 0.0469\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4710 - accuracy: 0.0391 - val_loss: 3.4603 - val_accuracy: 0.0625\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4646 - accuracy: 0.0234 - val_loss: 3.4610 - val_accuracy: 0.0625\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4696 - accuracy: 0.0391 - val_loss: 3.4618 - val_accuracy: 0.0625\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4598 - accuracy: 0.0469 - val_loss: 3.4625 - val_accuracy: 0.0781\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.4600 - accuracy: 0.0234 - val_loss: 3.4630 - val_accuracy: 0.0781\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4580 - accuracy: 0.0625 - val_loss: 3.4636 - val_accuracy: 0.0781\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4597 - accuracy: 0.0312 - val_loss: 3.4643 - val_accuracy: 0.0781\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4582 - accuracy: 0.0391 - val_loss: 3.4651 - val_accuracy: 0.0781\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.4562 - accuracy: 0.0430 - val_loss: 3.4656 - val_accuracy: 0.0781\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4560 - accuracy: 0.0508 - val_loss: 3.4662 - val_accuracy: 0.0625\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4600 - accuracy: 0.0352 - val_loss: 3.4670 - val_accuracy: 0.0469\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4511 - accuracy: 0.0547 - val_loss: 3.4677 - val_accuracy: 0.0156\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4581 - accuracy: 0.0547 - val_loss: 3.4688 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4536 - accuracy: 0.0391 - val_loss: 3.4697 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4499 - accuracy: 0.0625 - val_loss: 3.4706 - val_accuracy: 0.0156\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4479 - accuracy: 0.0312 - val_loss: 3.4712 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.4547 - accuracy: 0.0469 - val_loss: 3.4719 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4513 - accuracy: 0.0312 - val_loss: 3.4729 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4493 - accuracy: 0.0312 - val_loss: 3.4738 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4504 - accuracy: 0.0391 - val_loss: 3.4747 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4520 - accuracy: 0.0352 - val_loss: 3.4754 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4378 - accuracy: 0.0586 - val_loss: 3.4760 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4446 - accuracy: 0.0352 - val_loss: 3.4762 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4453 - accuracy: 0.0430 - val_loss: 3.4769 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.4435 - accuracy: 0.0703 - val_loss: 3.4775 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4394 - accuracy: 0.0430 - val_loss: 3.4779 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4431 - accuracy: 0.0469 - val_loss: 3.4782 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4444 - accuracy: 0.0352 - val_loss: 3.4787 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4390 - accuracy: 0.0273 - val_loss: 3.4794 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4426 - accuracy: 0.0391 - val_loss: 3.4801 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.4386 - accuracy: 0.0703 - val_loss: 3.4809 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4378 - accuracy: 0.0547 - val_loss: 3.4816 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4304 - accuracy: 0.0547 - val_loss: 3.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4459 - accuracy: 0.0391 - val_loss: 3.4830 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4358 - accuracy: 0.0391 - val_loss: 3.4836 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4365 - accuracy: 0.0391 - val_loss: 3.4843 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4351 - accuracy: 0.0469 - val_loss: 3.4850 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4354 - accuracy: 0.0508 - val_loss: 3.4860 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4346 - accuracy: 0.0430 - val_loss: 3.4872 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4352 - accuracy: 0.0430 - val_loss: 3.4881 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4389 - accuracy: 0.0352 - val_loss: 3.4887 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4405 - accuracy: 0.0430 - val_loss: 3.4896 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4248 - accuracy: 0.0469 - val_loss: 3.4901 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.4352 - accuracy: 0.0391 - val_loss: 3.4906 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4350 - accuracy: 0.0273 - val_loss: 3.4912 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4334 - accuracy: 0.0430 - val_loss: 3.4920 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4248 - accuracy: 0.0586 - val_loss: 3.4931 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4269 - accuracy: 0.0352 - val_loss: 3.4936 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4320 - accuracy: 0.0469 - val_loss: 3.4947 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4398 - accuracy: 0.0273 - val_loss: 3.4953 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4272 - accuracy: 0.0625 - val_loss: 3.4961 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4301 - accuracy: 0.0664 - val_loss: 3.4965 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4392 - accuracy: 0.0352 - val_loss: 3.4968 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4213 - accuracy: 0.0469 - val_loss: 3.4978 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4326 - accuracy: 0.0508 - val_loss: 3.4989 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4165 - accuracy: 0.0703 - val_loss: 3.5002 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4277 - accuracy: 0.0430 - val_loss: 3.5014 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4181 - accuracy: 0.0430 - val_loss: 3.5023 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4162 - accuracy: 0.0625 - val_loss: 3.5031 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4198 - accuracy: 0.0586 - val_loss: 3.5043 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.4196 - accuracy: 0.0625 - val_loss: 3.5055 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4247 - accuracy: 0.0508 - val_loss: 3.5066 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4229 - accuracy: 0.0312 - val_loss: 3.5077 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4196 - accuracy: 0.0547 - val_loss: 3.5093 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4188 - accuracy: 0.0469 - val_loss: 3.5107 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4119 - accuracy: 0.0469 - val_loss: 3.5123 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4099 - accuracy: 0.0430 - val_loss: 3.5138 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.4204 - accuracy: 0.0469 - val_loss: 3.5153 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4226 - accuracy: 0.0469 - val_loss: 3.5165 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4173 - accuracy: 0.0508 - val_loss: 3.5178 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4089 - accuracy: 0.0508 - val_loss: 3.5190 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4189 - accuracy: 0.0508 - val_loss: 3.5200 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.4209 - accuracy: 0.0547 - val_loss: 3.5207 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4179 - accuracy: 0.0547 - val_loss: 3.5209 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4048 - accuracy: 0.0547 - val_loss: 3.5217 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4151 - accuracy: 0.0508 - val_loss: 3.5223 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4140 - accuracy: 0.0508 - val_loss: 3.5233 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4129 - accuracy: 0.0547 - val_loss: 3.5245 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4018 - accuracy: 0.0547 - val_loss: 3.5256 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4078 - accuracy: 0.0625 - val_loss: 3.5266 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4079 - accuracy: 0.0625 - val_loss: 3.5278 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4029 - accuracy: 0.0391 - val_loss: 3.5291 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4119 - accuracy: 0.0508 - val_loss: 3.5301 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4122 - accuracy: 0.0430 - val_loss: 3.5310 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4059 - accuracy: 0.0547 - val_loss: 3.5321 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4074 - accuracy: 0.0508 - val_loss: 3.5331 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4179 - accuracy: 0.0430 - val_loss: 3.5339 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4140 - accuracy: 0.0664 - val_loss: 3.5352 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4094 - accuracy: 0.0430 - val_loss: 3.5363 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.4065 - accuracy: 0.0273 - val_loss: 3.5379 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3981 - accuracy: 0.0547 - val_loss: 3.5392 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4021 - accuracy: 0.0586 - val_loss: 3.5397 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4117 - accuracy: 0.0586 - val_loss: 3.5407 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4019 - accuracy: 0.0352 - val_loss: 3.5414 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4044 - accuracy: 0.0625 - val_loss: 3.5425 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3931 - accuracy: 0.0703 - val_loss: 3.5437 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3953 - accuracy: 0.0430 - val_loss: 3.5453 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4021 - accuracy: 0.0742 - val_loss: 3.5469 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3989 - accuracy: 0.0469 - val_loss: 3.5480 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4003 - accuracy: 0.0664 - val_loss: 3.5489 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3974 - accuracy: 0.0586 - val_loss: 3.5499 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3895 - accuracy: 0.0586 - val_loss: 3.5512 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3998 - accuracy: 0.0547 - val_loss: 3.5520 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3935 - accuracy: 0.0547 - val_loss: 3.5522 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4033 - accuracy: 0.0430 - val_loss: 3.5526 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3958 - accuracy: 0.0430 - val_loss: 3.5535 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4018 - accuracy: 0.0547 - val_loss: 3.5538 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3953 - accuracy: 0.0430 - val_loss: 3.5546 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3847 - accuracy: 0.0625 - val_loss: 3.5566 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3945 - accuracy: 0.0508 - val_loss: 3.5578 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.3856 - accuracy: 0.0586 - val_loss: 3.5591 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3982 - accuracy: 0.0391 - val_loss: 3.5599 - val_accuracy: 0.0156\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3885 - accuracy: 0.0469 - val_loss: 3.5608 - val_accuracy: 0.0156\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3871 - accuracy: 0.0703 - val_loss: 3.5616 - val_accuracy: 0.0156\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3827 - accuracy: 0.0469 - val_loss: 3.5623 - val_accuracy: 0.0156\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3823 - accuracy: 0.0547 - val_loss: 3.5636 - val_accuracy: 0.0156\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3944 - accuracy: 0.0586 - val_loss: 3.5650 - val_accuracy: 0.0156\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3854 - accuracy: 0.0586 - val_loss: 3.5659 - val_accuracy: 0.0156\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3885 - accuracy: 0.0430 - val_loss: 3.5670 - val_accuracy: 0.0156\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3796 - accuracy: 0.0391 - val_loss: 3.5687 - val_accuracy: 0.0156\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3842 - accuracy: 0.0664 - val_loss: 3.5707 - val_accuracy: 0.0156\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3875 - accuracy: 0.0469 - val_loss: 3.5719 - val_accuracy: 0.0156\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3932 - accuracy: 0.0586 - val_loss: 3.5741 - val_accuracy: 0.0156\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3838 - accuracy: 0.0273 - val_loss: 3.5752 - val_accuracy: 0.0156\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3976 - accuracy: 0.0508 - val_loss: 3.5765 - val_accuracy: 0.0156\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3820 - accuracy: 0.0703 - val_loss: 3.5768 - val_accuracy: 0.0156\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3766 - accuracy: 0.0469 - val_loss: 3.5785 - val_accuracy: 0.0156\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3691 - accuracy: 0.0625 - val_loss: 3.5805 - val_accuracy: 0.0156\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.3878 - accuracy: 0.0430 - val_loss: 3.5826 - val_accuracy: 0.0156\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3843 - accuracy: 0.0586 - val_loss: 3.5840 - val_accuracy: 0.0156\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3837 - accuracy: 0.0625 - val_loss: 3.5845 - val_accuracy: 0.0156\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3921 - accuracy: 0.0508 - val_loss: 3.5856 - val_accuracy: 0.0156\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 3.3762 - accuracy: 0.0547 - val_loss: 3.5874 - val_accuracy: 0.0156\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3854 - accuracy: 0.0430 - val_loss: 3.5875 - val_accuracy: 0.0156\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3846 - accuracy: 0.0469 - val_loss: 3.5883 - val_accuracy: 0.0156\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3860 - accuracy: 0.0391 - val_loss: 3.5892 - val_accuracy: 0.0156\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3813 - accuracy: 0.0625 - val_loss: 3.5897 - val_accuracy: 0.0156\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3686 - accuracy: 0.0664 - val_loss: 3.5901 - val_accuracy: 0.0156\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3799 - accuracy: 0.0625 - val_loss: 3.5917 - val_accuracy: 0.0156\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3850 - accuracy: 0.0469 - val_loss: 3.5917 - val_accuracy: 0.0156\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3708 - accuracy: 0.0547 - val_loss: 3.5926 - val_accuracy: 0.0156\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3702 - accuracy: 0.0547 - val_loss: 3.5940 - val_accuracy: 0.0156\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3775 - accuracy: 0.0430 - val_loss: 3.5953 - val_accuracy: 0.0156\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3781 - accuracy: 0.0742 - val_loss: 3.5957 - val_accuracy: 0.0156\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3690 - accuracy: 0.0703 - val_loss: 3.5968 - val_accuracy: 0.0156\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3665 - accuracy: 0.0703 - val_loss: 3.5983 - val_accuracy: 0.0156\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3799 - accuracy: 0.0391 - val_loss: 3.5994 - val_accuracy: 0.0156\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3661 - accuracy: 0.0664 - val_loss: 3.6008 - val_accuracy: 0.0156\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3797 - accuracy: 0.0352 - val_loss: 3.6014 - val_accuracy: 0.0156\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3666 - accuracy: 0.0625 - val_loss: 3.6021 - val_accuracy: 0.0156\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3627 - accuracy: 0.0469 - val_loss: 3.6036 - val_accuracy: 0.0156\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3681 - accuracy: 0.0469 - val_loss: 3.6044 - val_accuracy: 0.0156\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3704 - accuracy: 0.0430 - val_loss: 3.6050 - val_accuracy: 0.0156\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3668 - accuracy: 0.0547 - val_loss: 3.6062 - val_accuracy: 0.0156\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.3693 - accuracy: 0.0352 - val_loss: 3.6079 - val_accuracy: 0.0156\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3748 - accuracy: 0.0586 - val_loss: 3.6084 - val_accuracy: 0.0156\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3643 - accuracy: 0.0508 - val_loss: 3.6096 - val_accuracy: 0.0156\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3734 - accuracy: 0.0508 - val_loss: 3.6106 - val_accuracy: 0.0156\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3760 - accuracy: 0.0586 - val_loss: 3.6109 - val_accuracy: 0.0156\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3749 - accuracy: 0.0352 - val_loss: 3.6119 - val_accuracy: 0.0156\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3630 - accuracy: 0.0664 - val_loss: 3.6119 - val_accuracy: 0.0156\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3694 - accuracy: 0.0391 - val_loss: 3.6129 - val_accuracy: 0.0156\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3714 - accuracy: 0.0469 - val_loss: 3.6138 - val_accuracy: 0.0156\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3627 - accuracy: 0.0742 - val_loss: 3.6153 - val_accuracy: 0.0156\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3611 - accuracy: 0.0664 - val_loss: 3.6150 - val_accuracy: 0.0156\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3598 - accuracy: 0.0508 - val_loss: 3.6171 - val_accuracy: 0.0156\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3619 - accuracy: 0.0664 - val_loss: 3.6177 - val_accuracy: 0.0156\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3644 - accuracy: 0.0547 - val_loss: 3.6188 - val_accuracy: 0.0156\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3765 - accuracy: 0.0508 - val_loss: 3.6195 - val_accuracy: 0.0156\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3623 - accuracy: 0.0508 - val_loss: 3.6211 - val_accuracy: 0.0156\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3561 - accuracy: 0.0625 - val_loss: 3.6218 - val_accuracy: 0.0156\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3507 - accuracy: 0.0703 - val_loss: 3.6223 - val_accuracy: 0.0156\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3552 - accuracy: 0.0391 - val_loss: 3.6233 - val_accuracy: 0.0156\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3647 - accuracy: 0.0586 - val_loss: 3.6229 - val_accuracy: 0.0156\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 3.3562 - accuracy: 0.0508 - val_loss: 3.6236 - val_accuracy: 0.0156\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3544 - accuracy: 0.0586 - val_loss: 3.6242 - val_accuracy: 0.0156\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3657 - accuracy: 0.0430 - val_loss: 3.6246 - val_accuracy: 0.0156\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3507 - accuracy: 0.0664 - val_loss: 3.6251 - val_accuracy: 0.0156\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3582 - accuracy: 0.0391 - val_loss: 3.6246 - val_accuracy: 0.0156\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3613 - accuracy: 0.0391 - val_loss: 3.6254 - val_accuracy: 0.0156\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3458 - accuracy: 0.0664 - val_loss: 3.6262 - val_accuracy: 0.0156\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3616 - accuracy: 0.0547 - val_loss: 3.6265 - val_accuracy: 0.0156\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3485 - accuracy: 0.0742 - val_loss: 3.6281 - val_accuracy: 0.0156\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3522 - accuracy: 0.0586 - val_loss: 3.6291 - val_accuracy: 0.0156\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3377 - accuracy: 0.0625 - val_loss: 3.6316 - val_accuracy: 0.0156\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3465 - accuracy: 0.0352 - val_loss: 3.6324 - val_accuracy: 0.0156\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3493 - accuracy: 0.0664 - val_loss: 3.6338 - val_accuracy: 0.0156\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3596 - accuracy: 0.0664 - val_loss: 3.6357 - val_accuracy: 0.0156\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3560 - accuracy: 0.0508 - val_loss: 3.6375 - val_accuracy: 0.0156\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3446 - accuracy: 0.0586 - val_loss: 3.6395 - val_accuracy: 0.0156\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3557 - accuracy: 0.0508 - val_loss: 3.6426 - val_accuracy: 0.0156\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3549 - accuracy: 0.0508 - val_loss: 3.6445 - val_accuracy: 0.0156\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3571 - accuracy: 0.0508 - val_loss: 3.6446 - val_accuracy: 0.0156\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3509 - accuracy: 0.0547 - val_loss: 3.6446 - val_accuracy: 0.0156\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3550 - accuracy: 0.0430 - val_loss: 3.6446 - val_accuracy: 0.0156\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.3544 - accuracy: 0.0430 - val_loss: 3.6430 - val_accuracy: 0.0156\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3621 - accuracy: 0.0664 - val_loss: 3.6426 - val_accuracy: 0.0156\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3606 - accuracy: 0.0391 - val_loss: 3.6422 - val_accuracy: 0.0156\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3427 - accuracy: 0.0352 - val_loss: 3.6426 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3483 - accuracy: 0.0625 - val_loss: 3.6435 - val_accuracy: 0.0156\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3504 - accuracy: 0.0430 - val_loss: 3.6452 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3521 - accuracy: 0.0664 - val_loss: 3.6464 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3599 - accuracy: 0.0508 - val_loss: 3.6455 - val_accuracy: 0.0156\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3526 - accuracy: 0.0547 - val_loss: 3.6445 - val_accuracy: 0.0156\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3489 - accuracy: 0.0625 - val_loss: 3.6454 - val_accuracy: 0.0156\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3576 - accuracy: 0.0586 - val_loss: 3.6463 - val_accuracy: 0.0156\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.3541 - accuracy: 0.0469 - val_loss: 3.6486 - val_accuracy: 0.0156\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3507 - accuracy: 0.0547 - val_loss: 3.6488 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3479 - accuracy: 0.0469 - val_loss: 3.6494 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3665 - accuracy: 0.0469 - val_loss: 3.6495 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3377 - accuracy: 0.0508 - val_loss: 3.6486 - val_accuracy: 0.0156\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3463 - accuracy: 0.0508 - val_loss: 3.6491 - val_accuracy: 0.0156\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3650 - accuracy: 0.0391 - val_loss: 3.6488 - val_accuracy: 0.0156\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3396 - accuracy: 0.0547 - val_loss: 3.6487 - val_accuracy: 0.0156\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3523 - accuracy: 0.0547 - val_loss: 3.6492 - val_accuracy: 0.0156\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3404 - accuracy: 0.0391 - val_loss: 3.6497 - val_accuracy: 0.0156\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3374 - accuracy: 0.0547 - val_loss: 3.6506 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3386 - accuracy: 0.0586 - val_loss: 3.6518 - val_accuracy: 0.0156\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3759 - accuracy: 0.0508 - val_loss: 3.6531 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3477 - accuracy: 0.0703 - val_loss: 3.6580 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3530 - accuracy: 0.0586 - val_loss: 3.6598 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3407 - accuracy: 0.0781 - val_loss: 3.6607 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.3190 - accuracy: 0.0547 - val_loss: 3.6596 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3536 - accuracy: 0.0508 - val_loss: 3.6588 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3436 - accuracy: 0.0508 - val_loss: 3.6594 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3369 - accuracy: 0.0391 - val_loss: 3.6606 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3303 - accuracy: 0.0391 - val_loss: 3.6604 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3350 - accuracy: 0.0703 - val_loss: 3.6613 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3455 - accuracy: 0.0312 - val_loss: 3.6620 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3256 - accuracy: 0.0547 - val_loss: 3.6638 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3397 - accuracy: 0.0547 - val_loss: 3.6653 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3410 - accuracy: 0.0586 - val_loss: 3.6658 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3395 - accuracy: 0.0430 - val_loss: 3.6667 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3398 - accuracy: 0.0547 - val_loss: 3.6667 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3496 - accuracy: 0.0508 - val_loss: 3.6673 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3521 - accuracy: 0.0469 - val_loss: 3.6684 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3503 - accuracy: 0.0586 - val_loss: 3.6666 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3418 - accuracy: 0.0312 - val_loss: 3.6688 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.3528 - accuracy: 0.0586 - val_loss: 3.6716 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.3251 - accuracy: 0.0625 - val_loss: 3.6726 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3474 - accuracy: 0.0547 - val_loss: 3.6717 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3261 - accuracy: 0.0586 - val_loss: 3.6717 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3302 - accuracy: 0.0508 - val_loss: 3.6732 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3250 - accuracy: 0.0508 - val_loss: 3.6756 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3422 - accuracy: 0.0508 - val_loss: 3.6782 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3394 - accuracy: 0.0781 - val_loss: 3.6792 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3416 - accuracy: 0.0430 - val_loss: 3.6790 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3448 - accuracy: 0.0547 - val_loss: 3.6785 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3273 - accuracy: 0.0469 - val_loss: 3.6786 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3374 - accuracy: 0.0508 - val_loss: 3.6783 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3254 - accuracy: 0.0703 - val_loss: 3.6788 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3296 - accuracy: 0.0312 - val_loss: 3.6794 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3419 - accuracy: 0.0430 - val_loss: 3.6784 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3436 - accuracy: 0.0391 - val_loss: 3.6769 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3304 - accuracy: 0.0430 - val_loss: 3.6774 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.3167 - accuracy: 0.0781 - val_loss: 3.6779 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3147 - accuracy: 0.0469 - val_loss: 3.6801 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3316 - accuracy: 0.0547 - val_loss: 3.6813 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3171 - accuracy: 0.0703 - val_loss: 3.6830 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3133 - accuracy: 0.0625 - val_loss: 3.6841 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3201 - accuracy: 0.0625 - val_loss: 3.6862 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3244 - accuracy: 0.0664 - val_loss: 3.6865 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3207 - accuracy: 0.0703 - val_loss: 3.6892 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3241 - accuracy: 0.0469 - val_loss: 3.6905 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3262 - accuracy: 0.0508 - val_loss: 3.6929 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3246 - accuracy: 0.0469 - val_loss: 3.6934 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3160 - accuracy: 0.0625 - val_loss: 3.6929 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3161 - accuracy: 0.0586 - val_loss: 3.6932 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3311 - accuracy: 0.0469 - val_loss: 3.6924 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3081 - accuracy: 0.0586 - val_loss: 3.6914 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3068 - accuracy: 0.0703 - val_loss: 3.6910 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3287 - accuracy: 0.0508 - val_loss: 3.6919 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.3025 - accuracy: 0.0586 - val_loss: 3.6932 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3043 - accuracy: 0.0820 - val_loss: 3.6956 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3149 - accuracy: 0.0547 - val_loss: 3.6956 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3130 - accuracy: 0.0430 - val_loss: 3.6970 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3298 - accuracy: 0.0508 - val_loss: 3.6997 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3258 - accuracy: 0.0469 - val_loss: 3.7014 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3228 - accuracy: 0.0430 - val_loss: 3.7008 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3212 - accuracy: 0.0430 - val_loss: 3.7014 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3116 - accuracy: 0.0625 - val_loss: 3.7001 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3189 - accuracy: 0.0469 - val_loss: 3.6998 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3099 - accuracy: 0.0625 - val_loss: 3.6988 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3274 - accuracy: 0.0391 - val_loss: 3.7005 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3137 - accuracy: 0.0391 - val_loss: 3.6997 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3193 - accuracy: 0.0547 - val_loss: 3.7013 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3102 - accuracy: 0.0586 - val_loss: 3.7015 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.3249 - accuracy: 0.0469 - val_loss: 3.7008 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3281 - accuracy: 0.0352 - val_loss: 3.6999 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3181 - accuracy: 0.0859 - val_loss: 3.7017 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3324 - accuracy: 0.0508 - val_loss: 3.7037 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.2994 - accuracy: 0.0508 - val_loss: 3.7053 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3136 - accuracy: 0.0586 - val_loss: 3.7072 - val_accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7072 - accuracy: 0.0000e+00\n",
      "AcurÃ¡cia no conjunto de teste: 0.00%\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "data = pd.read_csv(\"dataset\\clean_data.csv\")\n",
    "\n",
    "data['labels'] = data['cores'].max() - data['cores']\n",
    "\n",
    "X = data[['input', 'average_runtime']].values\n",
    "y = data['labels'].values\n",
    "\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)  # NormalizaÃ§Ã£o Z-score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(2,)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.15),\n",
    "    layers.Dense(32, activation='softmax')\n",
    "])\n",
    "\n",
    "lr = 0.0001\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"AcurÃ¡cia no conjunto de teste: {test_acc * 100:.2f}%\")\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PC\\Desktop\\Nova pasta\\pascal-model-tcc\\train.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/Nova%20pasta/pascal-model-tcc/train.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/Nova%20pasta/pascal-model-tcc/train.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m matrix\u001b[39m=\u001b[39mconfusion_matrix(y_test, predictions)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/Nova%20pasta/pascal-model-tcc/train.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sns\u001b[39m.\u001b[39mheatmap(matrix, square\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, annot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fmt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39md\u001b[39m\u001b[39m'\u001b[39m, cbar\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/Nova%20pasta/pascal-model-tcc/train.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mtrue label\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix\u001b[39m(\n\u001b[0;32m    233\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    234\u001b[0m ):\n\u001b[0;32m    235\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \n\u001b[0;32m    237\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    319\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "matrix=confusion_matrix(y_test, predictions)\n",
    "sns.heatmap(matrix, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
